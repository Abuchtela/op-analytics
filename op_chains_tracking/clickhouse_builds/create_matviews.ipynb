{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of materialized view names\n",
    "mvs = [\n",
    "    {'mv_name': 'across_bridging_txs_v3', 'start_date': '2024-07-01', 'chains': ''},\n",
    "    # # {'mv_name': 'across_bridging_txs_v3_logs_only', 'start_date': '2024-07-01'},\n",
    "    # # {'mv_name': 'filtered_logs_l2s', 'start_date': ''},\n",
    "    # ### {'mv_name': 'erc20_transfers', 'start_date': ''},\n",
    "    # ### {'mv_name': 'native_eth_transfers', 'start_date': ''},\n",
    "    # ### {'mv_name': 'transactions_unique', 'start_date': ''},\n",
    "    # # {'mv_name': 'daily_aggregate_transactions_to', 'start_date': ''},\n",
    "    # {'mv_name': 'event_emitting_transactions_l2s', 'start_date': ''},\n",
    "    {'mv_name': 'weekly_retention_rate_temp', 'start_date': '2024-01-01', 'chains': 'superchain'},\n",
    "    {'mv_name': 'event_emitting_transactions_l2s_nofilter', 'start_date': '2024-01-01', 'chains': ''},\n",
    "    # {'mv_name': 'event_emitting_transactions_l2s_nofilter', 'start_date': '2024-01-01'},\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "set_days_batch_size = 7 #30\n",
    "\n",
    "optimize_all = False #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import traceback\n",
    "sys.path.append(\"../../helper_functions\")\n",
    "import clickhouse_utils as ch\n",
    "import opstack_metadata_utils as ops\n",
    "import goldsky_db_utils as gsb\n",
    "sys.path.pop()\n",
    "client = ch.connect_to_clickhouse_db()\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic0_maps = [\n",
    "        {'table_type': 'materialized', 'topic0_func': \"topic0\"},\n",
    "        {'table_type': 'raw', 'topic0_func': \"arrayElement(splitByString(',', topics), 1)\"}\n",
    "]\n",
    "    \n",
    "def check_topic0(client,chain):\n",
    "        sql = f\"SELECT topic0 FROM {chain}_logs limit 1\"\n",
    "        try:\n",
    "                client.command(sql)\n",
    "                topic0_func = next(item['topic0_func'] for item in topic0_maps if item['table_type'] == 'materialized')\n",
    "        except:\n",
    "                topic0_func = next(item['topic0_func'] for item in topic0_maps if item['table_type'] == 'raw')\n",
    "\n",
    "        return topic0_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_names = [item['mv_name'] for item in mvs]\n",
    "\n",
    "# Get Chain List\n",
    "chain_configs = ops.get_superchain_metadata_by_data_source('oplabs') # OPLabs db\n",
    "\n",
    "if client is None:\n",
    "        client = ch.connect_to_clickhouse_db()\n",
    "\n",
    "# Function to create ClickHouse view\n",
    "def get_chain_names_from_df(df):\n",
    "    return df['blockchain'].dropna().unique().tolist()\n",
    "\n",
    "# chain_configs = chain_configs[chain_configs['chain_name'] == 'xterio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain_name</th>\n",
       "      <th>display_name</th>\n",
       "      <th>mainnet_chain_id</th>\n",
       "      <th>chain_layer</th>\n",
       "      <th>alignment</th>\n",
       "      <th>da_layer</th>\n",
       "      <th>output_root_layer</th>\n",
       "      <th>gas_token</th>\n",
       "      <th>block_time_sec</th>\n",
       "      <th>public_mainnet_launch_date</th>\n",
       "      <th>op_chain_start</th>\n",
       "      <th>blockchain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zora</td>\n",
       "      <td>Zora</td>\n",
       "      <td>7777777.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-06-21</td>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>zora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base</td>\n",
       "      <td>Base</td>\n",
       "      <td>8453.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mode</td>\n",
       "      <td>Mode</td>\n",
       "      <td>34443.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lisk</td>\n",
       "      <td>Lisk</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>lisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>metal</td>\n",
       "      <td>Metal</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mint</td>\n",
       "      <td>Mint</td>\n",
       "      <td>185.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>mint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xterio</td>\n",
       "      <td>Xterio</td>\n",
       "      <td>2702128.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>altda</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>xterio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>polynomial</td>\n",
       "      <td>Polynomial Chain</td>\n",
       "      <td>8008.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>polynomial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>race</td>\n",
       "      <td>Race</td>\n",
       "      <td>6805.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>worldchain</td>\n",
       "      <td>World Chain</td>\n",
       "      <td>480.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>worldchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shape</td>\n",
       "      <td>Shape</td>\n",
       "      <td>360.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>op</td>\n",
       "      <td>OP Mainnet</td>\n",
       "      <td>10.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fraxtal</td>\n",
       "      <td>Fraxtal</td>\n",
       "      <td>252.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>fraxtalda</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>frxETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>fraxtal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>redstone</td>\n",
       "      <td>Redstone</td>\n",
       "      <td>690.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>op-plasma</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>redstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cyber</td>\n",
       "      <td>Cyber</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>eigenda</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>cyber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kroma</td>\n",
       "      <td>Kroma</td>\n",
       "      <td>255.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>kroma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ham</td>\n",
       "      <td>5112.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>unknown</td>\n",
       "      <td>base</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>swan</td>\n",
       "      <td>SwanChain</td>\n",
       "      <td>254.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>swan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lyra</td>\n",
       "      <td>Derive</td>\n",
       "      <td>957.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>celestia</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>lyra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>orderly</td>\n",
       "      <td>Orderly</td>\n",
       "      <td>291.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>celestia</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>2024-07-09</td>\n",
       "      <td>orderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bob</td>\n",
       "      <td>BOB (Build on Bitcoin)</td>\n",
       "      <td>60808.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum bitcoin</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-08-02</td>\n",
       "      <td>bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>automata</td>\n",
       "      <td>Automata</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>eigenda</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ATA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>sseed</td>\n",
       "      <td>SuperSeed</td>\n",
       "      <td>5330.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>superseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ink</td>\n",
       "      <td>Ink</td>\n",
       "      <td>57073.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>swell</td>\n",
       "      <td>Swell</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>swell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chain_name            display_name  mainnet_chain_id chain_layer  \\\n",
       "0         zora                    Zora         7777777.0          L2   \n",
       "1         base                    Base            8453.0          L2   \n",
       "2         mode                    Mode           34443.0          L2   \n",
       "4         lisk                    Lisk            1135.0          L2   \n",
       "5        metal                   Metal            1750.0          L2   \n",
       "6         mint                    Mint             185.0          L2   \n",
       "7       xterio                  Xterio         2702128.0          L2   \n",
       "8   polynomial        Polynomial Chain            8008.0          L2   \n",
       "9         race                    Race            6805.0          L2   \n",
       "10  worldchain             World Chain             480.0          L2   \n",
       "11       shape                   Shape             360.0          L2   \n",
       "16          op              OP Mainnet              10.0          L2   \n",
       "17     fraxtal                 Fraxtal             252.0          L2   \n",
       "18    redstone                Redstone             690.0          L2   \n",
       "19       cyber                   Cyber            7560.0          L2   \n",
       "20       kroma                   Kroma             255.0          L2   \n",
       "21         ham                     Ham            5112.0          L3   \n",
       "22        swan               SwanChain             254.0          L2   \n",
       "24        lyra                  Derive             957.0          L2   \n",
       "25     orderly                 Orderly             291.0          L2   \n",
       "26         bob  BOB (Build on Bitcoin)           60808.0          L2   \n",
       "32    automata                Automata           65536.0          L2   \n",
       "57       sseed               SuperSeed            5330.0          L2   \n",
       "76         ink                     Ink           57073.0          L2   \n",
       "78       swell                   Swell            1923.0          L2   \n",
       "\n",
       "   alignment          da_layer output_root_layer gas_token  block_time_sec  \\\n",
       "0   OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "1   OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "2   OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "4   OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "5   OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "6   OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "7   OP Chain             altda          ethereum       ETH             2.0   \n",
       "8   OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "9   OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "10  OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "11  OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "16  OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "17  OP Chain         fraxtalda          ethereum    frxETH             2.0   \n",
       "18  OP Chain         op-plasma          ethereum       ETH             2.0   \n",
       "19  OP Chain           eigenda          ethereum       ETH             2.0   \n",
       "20  OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "21  OP Chain           unknown              base       ETH             2.0   \n",
       "22  OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "24  OP Chain          celestia          ethereum       ETH             2.0   \n",
       "25  OP Chain          celestia          ethereum       ETH             2.0   \n",
       "26  OP Chain  ethereum bitcoin          ethereum       ETH             2.0   \n",
       "32  OP Chain           eigenda          ethereum       ATA             2.0   \n",
       "57  OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "76  OP Chain          ethereum          ethereum       ETH             1.0   \n",
       "78  OP Chain          ethereum          ethereum       ETH             2.0   \n",
       "\n",
       "   public_mainnet_launch_date op_chain_start  blockchain  \n",
       "0                  2023-06-21     2023-06-14        zora  \n",
       "1                  2023-08-09     2023-06-15        base  \n",
       "2                  2024-01-31     2024-01-31        mode  \n",
       "4                  2024-08-20     2024-05-03        lisk  \n",
       "5                  2024-03-29     2024-05-09       metal  \n",
       "6                  2024-07-01     2024-05-15        mint  \n",
       "7                  2024-06-11     2024-05-24      xterio  \n",
       "8                  2024-08-07     2024-06-10  polynomial  \n",
       "9                  2024-07-25     2024-07-08        race  \n",
       "10                 2024-10-17     2024-08-06  worldchain  \n",
       "11                 2024-09-30     2024-09-30       shape  \n",
       "16                 2021-11-11     2021-06-23          op  \n",
       "17                 2024-03-11     2024-02-01     fraxtal  \n",
       "18                 2024-05-01     2024-05-01    redstone  \n",
       "19                 2024-05-15     2024-05-15       cyber  \n",
       "20                 2023-09-06     2024-05-29       kroma  \n",
       "21                 2024-06-05     2024-06-05         ham  \n",
       "22                 2024-07-02     2024-06-17        swan  \n",
       "24                 2023-12-10     2024-06-18        lyra  \n",
       "25                 2024-01-21     2024-07-09     orderly  \n",
       "26                 2024-05-01     2024-08-02         bob  \n",
       "32                        NaN            NaN    automata  \n",
       "57                        NaN     2024-09-12   superseed  \n",
       "76                 2024-12-18            NaN         ink  \n",
       "78                 2024-12-19            NaN       swell  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-06\n"
     ]
    }
   ],
   "source": [
    "# List of chains\n",
    "# chains = get_chain_names_from_df(chain_configs)\n",
    "\n",
    "# Start date for backfilling\n",
    "start_date = datetime.date(2021, 11, 1)\n",
    "# start_date = datetime.date(2024, 5, 1)\n",
    "end_date = datetime.date.today() #+ datetime.timedelta(days=1)\n",
    "\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_start_date = start_date\n",
    "og_end_date = end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_from_file(mv_name):\n",
    "    try:\n",
    "        # Try to get the directory of the current script\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        # If __file__ is not defined (e.g., in Jupyter), use the current working directory\n",
    "        script_dir = os.getcwd()\n",
    "    \n",
    "    query_file_path = os.path.join(script_dir, 'mv_inputs', f'{mv_name}.sql')\n",
    "    # print(f\"Attempting to read query from: {query_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(query_file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Query file not found: {query_file_path}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_optimize_on_insert(option_int = 1):\n",
    "    client.command(f\"\"\"\n",
    "        SET optimize_on_insert = {option_int};\n",
    "        \"\"\")\n",
    "    print(f\"Set optimize_on_insert = {option_int}\")\n",
    "\n",
    "def do_optimize_final(client, chain_name, mv_name):\n",
    "    # print(f'Optimizing: {chain_name}_{mv_name}')\n",
    "    opcmd = f'OPTIMIZE TABLE {chain_name}_{mv_name} FINAL;'\n",
    "    print(opcmd)\n",
    "    client.command(opcmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import clickhouse_connect\n",
    "from clickhouse_connect.driver.exceptions import ClickHouseError\n",
    "\n",
    "def create_materialized_view(client, chain, mv_name, block_time = 2):\n",
    "    table_view_name = f'{chain}_{mv_name}'\n",
    "    full_view_name = f'{chain}_{mv_name}_mv'\n",
    "    create_file_name = f'{mv_name}_create'\n",
    "    print(full_view_name)\n",
    "    \n",
    "    # Check if create file exists\n",
    "    if not os.path.exists(f'mv_inputs/{create_file_name}.sql'):\n",
    "        print(f\"Table create file {create_file_name}.sql does not exist. Skipping table creation.\")\n",
    "    else:\n",
    "        try:\n",
    "            # Check if table already exists\n",
    "            result = client.query(f\"SHOW TABLES LIKE '{table_view_name}'\")\n",
    "            result_rows = list(result.result_rows)\n",
    "            if result_rows:\n",
    "                print(f\"Table {table_view_name} already exists. Skipping creation.\")\n",
    "            else:\n",
    "                # Create the table\n",
    "                create_query = get_query_from_file(create_file_name)\n",
    "                create_query = create_query.format(chain=chain, view_name=table_view_name)\n",
    "                client.command(create_query)\n",
    "                print(f\"Created table {table_view_name}\")\n",
    "        except ClickHouseError as e:\n",
    "            print(f\"Error creating table {table_view_name}: {str(e)}\")\n",
    "            return  # Exit the function if table creation fails\n",
    "\n",
    "    # Comment out matview since we're backfilling daily now\n",
    "    # try:\n",
    "    #     # Check if view already exists\n",
    "    #     result = client.query(f\"SHOW TABLES LIKE '{full_view_name}'\")\n",
    "    #     result_rows = list(result.result_rows)\n",
    "    #     if result_rows:\n",
    "    #         print(f\"Materialized view {full_view_name} already exists. Skipping creation.\")\n",
    "    #         return\n",
    "\n",
    "    #     query_template = get_query_from_file(f'{mv_name}_mv')\n",
    "    #     query = query_template.format(chain=chain, view_name=full_view_name, table_name=table_view_name, block_time_sec=block_time)\n",
    "    #     query = gsb.process_goldsky_sql(query)\n",
    "    #     # Save the query\n",
    "    #     output_folder = os.path.join(\"mv_outputs\", \"sql\")\n",
    "    #     os.makedirs(output_folder, exist_ok=True)\n",
    "    #     filename = f\"{mv_name}_mv.sql\"\n",
    "    #     file_path = os.path.join(output_folder, filename)\n",
    "    #     with open(file_path, 'w') as file:\n",
    "    #         file.write(query)\n",
    "    #     # print(query)\n",
    "    #     client.command(query)\n",
    "    #     print(f\"Created materialized view {full_view_name}\")\n",
    "    # except ClickHouseError as e:\n",
    "    #     print(f\"Error creating materialized view {full_view_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "def ensure_backfill_tracking_table_exists(client):\n",
    "    check_table_query = \"\"\"\n",
    "    SELECT 1 FROM system.tables \n",
    "    WHERE database = currentDatabase() AND name = 'backfill_tracking'\n",
    "    \"\"\"\n",
    "    result = client.query(check_table_query)\n",
    "    \n",
    "    if not result.result_rows:\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE backfill_tracking (\n",
    "            chain String,\n",
    "            mv_name String,\n",
    "            start_date Date,\n",
    "            end_date Date\n",
    "        ) ENGINE = MergeTree()\n",
    "        ORDER BY (chain, mv_name, start_date)\n",
    "        \"\"\"\n",
    "        client.command(create_table_query)\n",
    "        print(\"Created backfill_tracking table.\")\n",
    "    else:\n",
    "        print(\"backfill_tracking table already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# LEGACY FUNCTIONS\n",
    "# def backfill_data(client, chain, mv_name, end_date = end_date, block_time = 2, mod_start_date = start_date):\n",
    "#     full_view_name = f'{chain}_{mv_name}_mv'\n",
    "#     full_table_name = f'{chain}_{mv_name}'\n",
    "#     if mod_start_date == '':\n",
    "#         current_date_q = f\"SELECT DATE_TRUNC('day',MIN(timestamp)) AS start_dt FROM {chain}_blocks WHERE number = 1 AND is_deleted = 0\"\n",
    "#         current_date = client.query(current_date_q).result_rows[0][0].date()\n",
    "#     else:\n",
    "#         current_date = pd.to_datetime(mod_start_date).date()\n",
    "\n",
    "#     while current_date <= end_date:\n",
    "#         print(f\"{chain} - {mv_name}: Current date: {current_date} - End Date: {end_date}\")\n",
    "#         attempts = 1\n",
    "#         is_success = 0\n",
    "#         days_batch_size = set_days_batch_size\n",
    "        \n",
    "#         while (is_success == 0) & (attempts <= 3) :#& (current_date + datetime.timedelta(days=days_batch_size) <= end_date):\n",
    "#             if attempts == 1:\n",
    "#                 days_batch_size = set_days_batch_size\n",
    "#             elif attempts == 2:\n",
    "#                 days_batch_size = int( set_days_batch_size / 2 )\n",
    "#                 print(f'reset batch size to {days_batch_size}')\n",
    "#             else:\n",
    "#                 days_batch_size = 1\n",
    "#                 print(f'reset batch size to {days_batch_size}')\n",
    "            \n",
    "#             batch_size = datetime.timedelta(days=days_batch_size)\n",
    "#             print(f\"attempt: {attempts}\")\n",
    "#             batch_end = min(current_date + batch_size, end_date)\n",
    "#             # print(f'init batch end: {batch_end}')\n",
    "#             # print('checking backfill tracking')\n",
    "#             # Check if this range has been backfilled\n",
    "#             check_query_temp = get_query_from_file('backfill_check_query')\n",
    "#             check_query = check_query_temp.format(\n",
    "#                     mv_name=mv_name,\n",
    "#                     chain=chain,\n",
    "#                     start_date=current_date,\n",
    "#                     end_date=batch_end\n",
    "#                 )\n",
    "#             result = client.query(check_query)\n",
    "\n",
    "#             if result.result_rows: # Get date to start backfilling\n",
    "#                 latest_fill_start = result.result_rows[0][0]\n",
    "#                 # print(f\"Latest Fill Result: {latest_fill_start}\")\n",
    "#                 current_date = max(latest_fill_start, current_date)\n",
    "#                 batch_end = min(current_date + batch_size, end_date + datetime.timedelta(days = 1))\n",
    "#             else:\n",
    "#                 print(\"no backfill exists\")\n",
    "            \n",
    "#             # print(f'backfill check batch end: {batch_end}')\n",
    "#             # print(f\"Fill start: {current_date}\")\n",
    "\n",
    "#             # print(check_query)\n",
    "#             # print(result.result_rows)\n",
    "#             #Check if data already exists\n",
    "\n",
    "#             # Start 1 day back\n",
    "#             query_start_date = current_date - datetime.timedelta(days = 1)\n",
    "#             query_end_date = batch_end #+ datetime.timedelta(days = 1)\n",
    "\n",
    "\n",
    "#             if not result.result_rows:\n",
    "#                 # No record of backfill, proceed\n",
    "#                 query_template = get_query_from_file(f'{mv_name}_backfill')\n",
    "#                 query = query_template.format(\n",
    "#                     view_name=full_view_name,\n",
    "#                     chain=chain,\n",
    "#                     start_date=query_start_date,\n",
    "#                     end_date=query_end_date,\n",
    "#                     table_name = full_table_name,\n",
    "#                     block_time_sec = block_time\n",
    "#                 )\n",
    "#                 query = gsb.process_goldsky_sql(query)\n",
    "                \n",
    "#                 # print(query)\n",
    "#                 try:\n",
    "#                     # print(query)\n",
    "#                     # set_optimize_on_insert(0) # for runtime\n",
    "#                     print(f\"Starting backfill for {full_view_name} from {query_start_date} to {batch_end}\")\n",
    "\n",
    "#                     # # Save the query\n",
    "#                     # output_folder = os.path.join(\"mv_outputs\", \"sql\")\n",
    "#                     # os.makedirs(output_folder, exist_ok=True)\n",
    "#                     # filename = f\"{chain}_{mv_name}_backfill.sql\"\n",
    "#                     # file_path = os.path.join(output_folder, filename)\n",
    "#                     # with open(file_path, 'w') as file:\n",
    "#                     #     file.write(query)\n",
    "\n",
    "#                     client.command(query)\n",
    "#                     # Record the backfill\n",
    "#                     track_query = f\"\"\"\n",
    "#                     INSERT INTO backfill_tracking (chain, mv_name, start_date, end_date)\n",
    "#                     VALUES ('{chain}', '{mv_name}', toDate('{current_date}'), toDate('{batch_end}'))\n",
    "#                     \"\"\"\n",
    "#                     client.command(track_query)\n",
    "                    \n",
    "#                     print(f\"Backfilled data for {full_view_name} from {query_start_date} to {batch_end}\")\n",
    "\n",
    "#                     # Optimize the newly backfilled partition\n",
    "#                     # optimize_partition(client, full_view_name, current_date, batch_end)\n",
    "#                     is_success = 1\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error during backfill for {full_view_name} from {current_date} to {batch_end}: {str(e)}\")\n",
    "#                     attempts += 1\n",
    "#                 time.sleep(1)\n",
    "#             else:\n",
    "#                 print(f\"Data already backfilled for {full_view_name} from {current_date} to {batch_end}. Skipping.\")\n",
    "#                 is_success = 1\n",
    "#                 # if optimize_all:\n",
    "#                 #     optimize_partition(client, full_view_name, current_date, batch_end)\n",
    "#         # print(f\"Current Date: {current_date}, Batch End: {batch_end}\")\n",
    "#         current_date = max(batch_end,current_date + datetime.timedelta(days=1))\n",
    "\n",
    "        # print(f\"New Current Date: {current_date}\")\n",
    "\n",
    "# def optimize_partition(client, full_view_name, start_date, end_date):\n",
    "#     # First, let's get the actual partition names\n",
    "#     partition_query = f\"\"\"\n",
    "#     SELECT DISTINCT partition\n",
    "#     FROM system.parts\n",
    "#     WHERE table = '{full_view_name.split('.')[-1]}'\n",
    "#       AND database = '{full_view_name.split('.')[0]}'\n",
    "#       AND active\n",
    "#     ORDER BY partition\n",
    "#     \"\"\"\n",
    "#     print(partition_query)\n",
    "#     partitions = [row[0] for row in client.query(partition_query).result_rows]\n",
    "    \n",
    "#     print(f\"Available partitions for {full_view_name}: {partitions}\")\n",
    "\n",
    "#     # Filter partitions within our date range\n",
    "#     start_partition = start_date.strftime('%Y%m')\n",
    "#     end_partition = end_date.strftime('%Y%m')\n",
    "#     partitions_to_optimize = [p for p in partitions if start_partition <= p <= end_partition]\n",
    "\n",
    "#     if not partitions_to_optimize:\n",
    "#         print(f\"No partitions found for {full_view_name} between {start_date} and {end_date}\")\n",
    "#         return\n",
    "\n",
    "#     try:\n",
    "#         for partition in partitions_to_optimize:\n",
    "#             optimize_query = f\"\"\"\n",
    "#             OPTIMIZE TABLE {full_view_name} \n",
    "#             PARTITION '{partition}'\n",
    "#             FINAL SETTINGS max_execution_time = 3000\n",
    "#             \"\"\"\n",
    "#             print(f\"Attempting to optimize {full_view_name} for partition {partition}\")\n",
    "#             client.command(optimize_query)\n",
    "#             print(f\"Successfully optimized partition {partition} for {full_view_name}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error executing OPTIMIZE TABLE for {full_view_name}\")\n",
    "#         print(f\"  Partition: {partition}\")\n",
    "#         print(f\"  Date range: {start_date} to {end_date}\")\n",
    "#         print(f\"  Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfill_data(client, chain, mv_name, end_date, block_time=2, mod_start_date='', set_days_batch_size=7):\n",
    "    full_view_name = f'{chain}_{mv_name}_mv'\n",
    "    full_table_name = f'{chain}_{mv_name}'\n",
    "\n",
    "    topic0_func = check_topic0(client, chain)\n",
    "    \n",
    "    # Check on Date Ranges\n",
    "    current_date_q = f\"\"\"\n",
    "    SELECT \n",
    "        DATE_TRUNC('day', MIN(timestamp)) AS start_dt, \n",
    "        DATE_TRUNC('day', MAX(timestamp)) AS end_dt \n",
    "    FROM {chain}_blocks \n",
    "    WHERE number >= 1 AND is_deleted = 0\n",
    "    \"\"\"\n",
    "    result = client.query(current_date_q).result_rows\n",
    "    \n",
    "    if result and result[0][0] is not None and result[0][1] is not None:\n",
    "        start_date_result = max(result[0][0].date() , og_start_date) # handle for corrupt timestamp\n",
    "        end_date_result = min( result[0][1].date(), og_end_date) # handle for corrupt timestamp\n",
    "        print(f'start_date_result {start_date_result} - end_date_result {end_date_result}')\n",
    "    else:\n",
    "        start_date_result = start_date\n",
    "        end_date_result = end_date\n",
    "\n",
    "    # Determine start date\n",
    "    if mod_start_date == '':\n",
    "        start_date = start_date_result\n",
    "    else:\n",
    "        start_date = pd.to_datetime(mod_start_date).date()\n",
    "\n",
    "    start_date = start_date - datetime.timedelta(days=1) #ensure we fill in prior day\n",
    "\n",
    "    # Determine end date\n",
    "    end_date = end_date_result\n",
    "\n",
    "    # Print out resulting range\n",
    "    print(f\"Checking Backfill for {full_view_name} from {start_date} to {end_date}\")\n",
    "\n",
    "    # Fetch all existing backfill ranges\n",
    "    backfill_query = f\"\"\"\n",
    "    SELECT start_date, end_date\n",
    "    FROM backfill_tracking\n",
    "    WHERE chain = '{chain}' AND mv_name = '{mv_name}'\n",
    "    AND start_date >= toDate('{start_date}')\n",
    "    ORDER BY start_date\n",
    "    \"\"\"\n",
    "    backfill_ranges = client.query(backfill_query).result_rows\n",
    "\n",
    "    # Convert to list of tuples and sort\n",
    "    backfill_ranges = sorted([(row[0], row[1]) for row in backfill_ranges])\n",
    "\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        # Find the next date that needs backfilling\n",
    "        while current_date <= end_date:\n",
    "            # print(f'check: start {start_date}, current {current_date}, end {end_date}')\n",
    "            is_backfilled = any(bf_start <= current_date <= bf_end for bf_start, bf_end in backfill_ranges)\n",
    "            if not is_backfilled:\n",
    "                break\n",
    "            current_date += datetime.timedelta(days=1)\n",
    "        \n",
    "        if current_date > end_date:\n",
    "            print(f\"All dates up to {end_date} have been backfilled.\")\n",
    "            break\n",
    "\n",
    "        # Determine the batch end date\n",
    "        batch_end = min(current_date + datetime.timedelta(days=set_days_batch_size - 1), end_date)\n",
    "        \n",
    "        # Adjust batch_end if it overlaps with an existing backfill range\n",
    "        for bf_start, bf_end in backfill_ranges:\n",
    "            if current_date < bf_start <= batch_end:\n",
    "                batch_end = bf_start - datetime.timedelta(days=1)\n",
    "                break\n",
    "\n",
    "        # Perform the backfill\n",
    "        attempts = 1\n",
    "        query_start_date = current_date - datetime.timedelta(days=1)\n",
    "\n",
    "        while attempts <= 3:\n",
    "            try:\n",
    "                query_template = get_query_from_file(f'{mv_name}_backfill')\n",
    "                query = query_template.format(\n",
    "                    view_name=full_view_name,\n",
    "                    chain=chain,\n",
    "                    start_date=query_start_date,\n",
    "                    end_date=batch_end,\n",
    "                    table_name=full_table_name,\n",
    "                    block_time_sec=block_time,\n",
    "                    topic0_func=topic0_func\n",
    "                )\n",
    "                query = gsb.process_goldsky_sql(query)\n",
    "                \n",
    "                print(f\"Starting backfill for {full_view_name} from {query_start_date} to {batch_end}\")\n",
    "                client.command(query)\n",
    "                \n",
    "                # Record the backfill\n",
    "                track_query = f\"\"\"\n",
    "                INSERT INTO backfill_tracking (chain, mv_name, start_date, end_date)\n",
    "                VALUES ('{chain}', '{mv_name}', toDate('{query_start_date}'), toDate('{batch_end}'))\n",
    "                \"\"\"\n",
    "                client.command(track_query)\n",
    "                \n",
    "                print(f\"Backfilled data for {full_view_name} from {query_start_date} to {batch_end}\")\n",
    "                \n",
    "                # Update backfill_ranges with the new range\n",
    "                backfill_ranges.append((current_date, batch_end))\n",
    "                backfill_ranges.sort()\n",
    "                \n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error during backfill for {full_view_name} from {current_date} to {batch_end}: {str(e)}\")\n",
    "                attempts += 1\n",
    "                batch_end = min(current_date + datetime.timedelta(days=set_days_batch_size // (2 ** (attempts - 1))), end_date)\n",
    "            time.sleep(1)\n",
    "\n",
    "        current_date = batch_end + datetime.timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach_reset_materialized_view(client, chain, mv_name):\n",
    "    table_view_name = f'{chain}_{mv_name}'\n",
    "    full_view_name = f'{chain}_{mv_name}_mv'\n",
    "    create_file_name = f'{mv_name}_create'\n",
    "    print(full_view_name)\n",
    "    query_template = get_query_from_file(f'{mv_name}_mv')\n",
    "    query = query_template.format(chain=chain, view_name=full_view_name, table_name=table_view_name, block_time_sec=block_time)\n",
    "    query = gsb.process_goldsky_sql(query)\n",
    "    client.command(query)\n",
    "    print(f\"Updated materialized view {full_view_name}\")\n",
    "\n",
    "    # dt_cmd = f\"DETACH TABLE PERMANENTLY {full_view_name}\"\n",
    "    # dt_cmd = f\"ALTER TABLE {full_view_name} MODIFY QUERY SELECT 1 WHERE 0\"\n",
    "\n",
    "    # print(dt_cmd)\n",
    "    client.command(dt_cmd)\n",
    "    print(f\"Detached table {full_view_name}\")\n",
    "\n",
    "def reset_materialized_view(client, chain, mv_name,):\n",
    "    full_view_name = f'{chain}_{mv_name}_mv'\n",
    "    table_name = f'{chain}_{mv_name}'\n",
    "\n",
    "    try:\n",
    "        # Drop the existing materialized view\n",
    "        client.command(f\"DROP TABLE IF EXISTS {full_view_name}\")\n",
    "        # client.command(f\"DROP MATERIALIZED VIEW IF EXISTS {full_view_name}\")\n",
    "        print(f\"Dropped materialized view {full_view_name}\")\n",
    "\n",
    "        # Drop the existing materialized view\n",
    "        client.command(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        client.command(f\"DROP TABLE IF EXISTS {full_view_name}\")\n",
    "        print(f\"Dropped table {table_name}\")\n",
    "\n",
    "        # Clear the backfill tracking for this view\n",
    "        bf_delete = f\"\"\"\n",
    "        ALTER TABLE backfill_tracking \n",
    "        DELETE WHERE chain = '{chain}' AND mv_name = '{mv_name}'\n",
    "        \"\"\"\n",
    "        # print(bf_delete)\n",
    "        client.command(bf_delete)\n",
    "\n",
    "        print(f\"Cleared backfill tracking for {full_view_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error resetting materialized view {full_view_name}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_backfill_gaps(client):\n",
    "    query = get_query_from_file('find_backfill_gaps')\n",
    "    result = client.query(query)\n",
    "\n",
    "    if result.result_rows:\n",
    "        print(\"Backfill gaps found:\")\n",
    "        print(\"Chain | Table/View Name | Gap Start | Gap End\")\n",
    "        print(\"-\" * 50)\n",
    "        for row in result.result_rows:\n",
    "            print(f\"{row[0]} | {row[1]} | {row[2]} | {row[3]}\")\n",
    "    else:\n",
    "        print(\"No backfill gaps found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped materialized view ink_across_bridging_txs_v3_mv\n",
      "Dropped table ink_across_bridging_txs_v3\n",
      "Cleared backfill tracking for ink_across_bridging_txs_v3_mv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # # # # # # reset a single chain\n",
    "# reset_materialized_view(client, 'ink', 'across_bridging_txs_v3')\n",
    "\n",
    "# # # To reset a view\n",
    "# for row in chain_configs.itertuples(index=False):\n",
    "#         chain = row.chain_name\n",
    "#         reset_materialized_view(client, chain, 'across_bridging_txs_v3')\n",
    "\n",
    "\n",
    "# # # # # # # # # # # # for mv in mv_names:\n",
    "# # # # # # # # # # # #         # print(row)\n",
    "# # # # # # # # # # # #         reset_materialized_view(client, 'bob', mv)\n",
    "\n",
    "\n",
    "# # # # # # # # Clear all\n",
    "# # # # # # # # mv_names\n",
    "# # # # # # # # for row in chain_configs.itertuples(index=False):\n",
    "# # # # # # # #         for mv in mv_names:\n",
    "# # # # # # # #                 chain = row.chain_name\n",
    "# # # # # # # #                 reset_materialized_view(client, chain, mv)\n",
    "\n",
    "# # # Detach all\n",
    "# # detach_reset_materialized_view\n",
    "# # for row in chain_configs.itertuples(index=False):\n",
    "# #         for mv in mv_names:\n",
    "# #                 chain = row.chain_name\n",
    "# #                 detach_reset_materialized_view(client, chain, mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimize\n",
    "# for row in chain_configs.itertuples(index=False):\n",
    "#         for mv in mv_names:\n",
    "#                 chain = row.chain_name\n",
    "#                 do_optimize_final(client, chain, mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_chain_configs = chain_configs\n",
    "chain_configs_if_agg = pd.DataFrame({\n",
    "    'blockchain': ['superchain'],\n",
    "    'block_time_sec': [2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# og_chain_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backfill_tracking table already exists.\n",
      "Pandas(chain_name='zora', display_name='Zora', mainnet_chain_id=7777777.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2023-06-21', op_chain_start='2023-06-14', blockchain='zora')\n",
      "Processing chain: zora - across_bridging_txs_v3\n",
      "create matview\n",
      "zora_across_bridging_txs_v3_mv\n",
      "Table zora_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2023-06-13 - end_date_result 2025-01-06\n",
      "Checking Backfill for zora_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for zora_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for zora_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='base', display_name='Base', mainnet_chain_id=8453.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2023-08-09', op_chain_start='2023-06-15', blockchain='base')\n",
      "Processing chain: base - across_bridging_txs_v3\n",
      "create matview\n",
      "base_across_bridging_txs_v3_mv\n",
      "Table base_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2023-06-15 - end_date_result 2025-01-06\n",
      "Checking Backfill for base_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for base_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for base_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='mode', display_name='Mode', mainnet_chain_id=34443.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-01-31', op_chain_start='2024-01-31', blockchain='mode')\n",
      "Processing chain: mode - across_bridging_txs_v3\n",
      "create matview\n",
      "mode_across_bridging_txs_v3_mv\n",
      "Table mode_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2023-11-16 - end_date_result 2025-01-06\n",
      "Checking Backfill for mode_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for mode_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for mode_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='lisk', display_name='Lisk', mainnet_chain_id=1135.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-08-20', op_chain_start='2024-05-03', blockchain='lisk')\n",
      "Processing chain: lisk - across_bridging_txs_v3\n",
      "create matview\n",
      "lisk_across_bridging_txs_v3_mv\n",
      "Table lisk_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-05-03 - end_date_result 2025-01-06\n",
      "Checking Backfill for lisk_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for lisk_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for lisk_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='metal', display_name='Metal', mainnet_chain_id=1750.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-03-29', op_chain_start='2024-05-09', blockchain='metal')\n",
      "Processing chain: metal - across_bridging_txs_v3\n",
      "create matview\n",
      "metal_across_bridging_txs_v3_mv\n",
      "Table metal_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-03-27 - end_date_result 2025-01-06\n",
      "Checking Backfill for metal_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for metal_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for metal_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='mint', display_name='Mint', mainnet_chain_id=185.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-07-01', op_chain_start='2024-05-15', blockchain='mint')\n",
      "Processing chain: mint - across_bridging_txs_v3\n",
      "create matview\n",
      "mint_across_bridging_txs_v3_mv\n",
      "Table mint_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-05-13 - end_date_result 2025-01-06\n",
      "Checking Backfill for mint_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for mint_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for mint_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='xterio', display_name='Xterio', mainnet_chain_id=2702128.0, chain_layer='L2', alignment='OP Chain', da_layer='altda', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-06-11', op_chain_start='2024-05-24', blockchain='xterio')\n",
      "Processing chain: xterio - across_bridging_txs_v3\n",
      "create matview\n",
      "xterio_across_bridging_txs_v3_mv\n",
      "Table xterio_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-05-24 - end_date_result 2025-01-06\n",
      "Checking Backfill for xterio_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for xterio_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for xterio_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='polynomial', display_name='Polynomial Chain', mainnet_chain_id=8008.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-08-07', op_chain_start='2024-06-10', blockchain='polynomial')\n",
      "Processing chain: polynomial - across_bridging_txs_v3\n",
      "create matview\n",
      "polynomial_across_bridging_txs_v3_mv\n",
      "Table polynomial_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-06-10 - end_date_result 2025-01-06\n",
      "Checking Backfill for polynomial_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for polynomial_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for polynomial_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='race', display_name='Race', mainnet_chain_id=6805.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-07-25', op_chain_start='2024-07-08', blockchain='race')\n",
      "Processing chain: race - across_bridging_txs_v3\n",
      "create matview\n",
      "race_across_bridging_txs_v3_mv\n",
      "Table race_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-07-08 - end_date_result 2025-01-06\n",
      "Checking Backfill for race_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for race_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for race_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='worldchain', display_name='World Chain', mainnet_chain_id=480.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-10-17', op_chain_start='2024-08-06', blockchain='worldchain')\n",
      "Processing chain: worldchain - across_bridging_txs_v3\n",
      "create matview\n",
      "worldchain_across_bridging_txs_v3_mv\n",
      "Table worldchain_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-06-25 - end_date_result 2025-01-06\n",
      "Checking Backfill for worldchain_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for worldchain_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for worldchain_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='shape', display_name='Shape', mainnet_chain_id=360.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-09-30', op_chain_start='2024-09-30', blockchain='shape')\n",
      "Processing chain: shape - across_bridging_txs_v3\n",
      "create matview\n",
      "shape_across_bridging_txs_v3_mv\n",
      "Table shape_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-07-23 - end_date_result 2025-01-06\n",
      "Checking Backfill for shape_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for shape_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for shape_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='op', display_name='OP Mainnet', mainnet_chain_id=10.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2021-11-11', op_chain_start='2021-06-23', blockchain='op')\n",
      "Processing chain: op - across_bridging_txs_v3\n",
      "create matview\n",
      "op_across_bridging_txs_v3_mv\n",
      "Table op_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2021-11-11 - end_date_result 2025-01-06\n",
      "Checking Backfill for op_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for op_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for op_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='fraxtal', display_name='Fraxtal', mainnet_chain_id=252.0, chain_layer='L2', alignment='OP Chain', da_layer='fraxtalda', output_root_layer='ethereum', gas_token='frxETH', block_time_sec=2.0, public_mainnet_launch_date='2024-03-11', op_chain_start='2024-02-01', blockchain='fraxtal')\n",
      "Processing chain: fraxtal - across_bridging_txs_v3\n",
      "create matview\n",
      "fraxtal_across_bridging_txs_v3_mv\n",
      "Table fraxtal_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-02-01 - end_date_result 2025-01-06\n",
      "Checking Backfill for fraxtal_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for fraxtal_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for fraxtal_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='redstone', display_name='Redstone', mainnet_chain_id=690.0, chain_layer='L2', alignment='OP Chain', da_layer='op-plasma', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-05-01', op_chain_start='2024-05-01', blockchain='redstone')\n",
      "Processing chain: redstone - across_bridging_txs_v3\n",
      "create matview\n",
      "redstone_across_bridging_txs_v3_mv\n",
      "Table redstone_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-04-03 - end_date_result 2025-01-06\n",
      "Checking Backfill for redstone_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for redstone_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for redstone_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='cyber', display_name='Cyber', mainnet_chain_id=7560.0, chain_layer='L2', alignment='OP Chain', da_layer='eigenda', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-05-15', op_chain_start='2024-05-15', blockchain='cyber')\n",
      "Processing chain: cyber - across_bridging_txs_v3\n",
      "create matview\n",
      "cyber_across_bridging_txs_v3_mv\n",
      "Table cyber_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-04-18 - end_date_result 2025-01-06\n",
      "Checking Backfill for cyber_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for cyber_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for cyber_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='kroma', display_name='Kroma', mainnet_chain_id=255.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2023-09-06', op_chain_start='2024-05-29', blockchain='kroma')\n",
      "Processing chain: kroma - across_bridging_txs_v3\n",
      "create matview\n",
      "kroma_across_bridging_txs_v3_mv\n",
      "Table kroma_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2023-09-05 - end_date_result 2025-01-06\n",
      "Checking Backfill for kroma_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for kroma_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for kroma_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='ham', display_name='Ham', mainnet_chain_id=5112.0, chain_layer='L3', alignment='OP Chain', da_layer='unknown', output_root_layer='base', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-06-05', op_chain_start='2024-06-05', blockchain='ham')\n",
      "Processing chain: ham - across_bridging_txs_v3\n",
      "create matview\n",
      "ham_across_bridging_txs_v3_mv\n",
      "Table ham_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-05-24 - end_date_result 2025-01-06\n",
      "Checking Backfill for ham_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for ham_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for ham_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='swan', display_name='SwanChain', mainnet_chain_id=254.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-07-02', op_chain_start='2024-06-17', blockchain='swan')\n",
      "Processing chain: swan - across_bridging_txs_v3\n",
      "create matview\n",
      "swan_across_bridging_txs_v3_mv\n",
      "Table swan_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-06-17 - end_date_result 2025-01-06\n",
      "Checking Backfill for swan_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for swan_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for swan_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='lyra', display_name='Derive', mainnet_chain_id=957.0, chain_layer='L2', alignment='OP Chain', da_layer='celestia', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2023-12-10', op_chain_start='2024-06-18', blockchain='lyra')\n",
      "Processing chain: lyra - across_bridging_txs_v3\n",
      "create matview\n",
      "lyra_across_bridging_txs_v3_mv\n",
      "Table lyra_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2023-11-15 - end_date_result 2025-01-06\n",
      "Checking Backfill for lyra_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for lyra_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for lyra_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='orderly', display_name='Orderly', mainnet_chain_id=291.0, chain_layer='L2', alignment='OP Chain', da_layer='celestia', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-01-21', op_chain_start='2024-07-09', blockchain='orderly')\n",
      "Processing chain: orderly - across_bridging_txs_v3\n",
      "create matview\n",
      "orderly_across_bridging_txs_v3_mv\n",
      "Table orderly_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2023-10-06 - end_date_result 2025-01-06\n",
      "Checking Backfill for orderly_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for orderly_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for orderly_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='bob', display_name='BOB (Build on Bitcoin)', mainnet_chain_id=60808.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum bitcoin', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-05-01', op_chain_start='2024-08-02', blockchain='bob')\n",
      "Processing chain: bob - across_bridging_txs_v3\n",
      "create matview\n",
      "bob_across_bridging_txs_v3_mv\n",
      "Table bob_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-04-11 - end_date_result 2025-01-06\n",
      "Checking Backfill for bob_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for bob_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for bob_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='automata', display_name='Automata', mainnet_chain_id=65536.0, chain_layer='L2', alignment='OP Chain', da_layer='eigenda', output_root_layer='ethereum', gas_token='ATA', block_time_sec=2.0, public_mainnet_launch_date=nan, op_chain_start=nan, blockchain='automata')\n",
      "Processing chain: automata - across_bridging_txs_v3\n",
      "create matview\n",
      "automata_across_bridging_txs_v3_mv\n",
      "Table automata_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-07-17 - end_date_result 2025-01-06\n",
      "Checking Backfill for automata_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for automata_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for automata_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='sseed', display_name='SuperSeed', mainnet_chain_id=5330.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date=nan, op_chain_start='2024-09-12', blockchain='superseed')\n",
      "Processing chain: superseed - across_bridging_txs_v3\n",
      "create matview\n",
      "superseed_across_bridging_txs_v3_mv\n",
      "Table superseed_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-09-12 - end_date_result 2025-01-06\n",
      "Checking Backfill for superseed_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for superseed_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for superseed_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Pandas(chain_name='ink', display_name='Ink', mainnet_chain_id=57073.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=1.0, public_mainnet_launch_date='2024-12-18', op_chain_start=nan, blockchain='ink')\n",
      "Processing chain: ink - across_bridging_txs_v3\n",
      "create matview\n",
      "ink_across_bridging_txs_v3_mv\n",
      "Created table ink_across_bridging_txs_v3\n",
      "create backfill\n",
      "start_date_result 2024-12-06 - end_date_result 2025-01-06\n",
      "Checking Backfill for ink_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for ink_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-29\n",
      "Backfilled data for ink_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-29\n",
      "Starting backfill for ink_across_bridging_txs_v3_mv from 2024-07-29 to 2024-08-28\n",
      "Backfilled data for ink_across_bridging_txs_v3_mv from 2024-07-29 to 2024-08-28\n",
      "Starting backfill for ink_across_bridging_txs_v3_mv from 2024-08-28 to 2024-09-27\n",
      "Backfilled data for ink_across_bridging_txs_v3_mv from 2024-08-28 to 2024-09-27\n",
      "Starting backfill for ink_across_bridging_txs_v3_mv from 2024-09-27 to 2024-10-27\n",
      "Backfilled data for ink_across_bridging_txs_v3_mv from 2024-09-27 to 2024-10-27\n",
      "Starting backfill for ink_across_bridging_txs_v3_mv from 2024-10-27 to 2024-11-26\n",
      "Backfilled data for ink_across_bridging_txs_v3_mv from 2024-10-27 to 2024-11-26\n",
      "Starting backfill for ink_across_bridging_txs_v3_mv from 2024-11-26 to 2024-12-26\n",
      "Backfilled data for ink_across_bridging_txs_v3_mv from 2024-11-26 to 2024-12-26\n",
      "Starting backfill for ink_across_bridging_txs_v3_mv from 2024-12-26 to 2025-01-06\n",
      "Backfilled data for ink_across_bridging_txs_v3_mv from 2024-12-26 to 2025-01-06\n",
      "Pandas(chain_name='swell', display_name='Swell', mainnet_chain_id=1923.0, chain_layer='L2', alignment='OP Chain', da_layer='ethereum', output_root_layer='ethereum', gas_token='ETH', block_time_sec=2.0, public_mainnet_launch_date='2024-12-19', op_chain_start=nan, blockchain='swell')\n",
      "Processing chain: swell - across_bridging_txs_v3\n",
      "create matview\n",
      "swell_across_bridging_txs_v3_mv\n",
      "Table swell_across_bridging_txs_v3 already exists. Skipping creation.\n",
      "create backfill\n",
      "start_date_result 2024-11-27 - end_date_result 2025-01-06\n",
      "Checking Backfill for swell_across_bridging_txs_v3_mv from 2024-06-30 to 2025-01-06\n",
      "Starting backfill for swell_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "Backfilled data for swell_across_bridging_txs_v3_mv from 2024-06-29 to 2024-07-28\n",
      "All dates up to 2025-01-06 have been backfilled.\n",
      "Completed processing for swell\n",
      "Pandas(chain_name='superchain', block_time_sec=2)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pandas' object has no attribute 'blockchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chain_row \u001b[38;5;129;01min\u001b[39;00m chain_configs\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chain_row)\n\u001b[0;32m---> 13\u001b[0m     chain \u001b[38;5;241m=\u001b[39m \u001b[43mchain_row\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblockchain\u001b[49m\n\u001b[1;32m     14\u001b[0m     block_time \u001b[38;5;241m=\u001b[39m chain_row\u001b[38;5;241m.\u001b[39mblock_time_sec\n\u001b[1;32m     16\u001b[0m     mv_name \u001b[38;5;241m=\u001b[39m mv_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmv_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pandas' object has no attribute 'blockchain'"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "ensure_backfill_tracking_table_exists(client)\n",
    "\n",
    "for mv_row in mvs:\n",
    "\n",
    "    if mv_row['chains'] == 'superchain':\n",
    "        chain_configs = chain_configs_if_agg\n",
    "    else:\n",
    "        chain_configs = og_chain_configs\n",
    "        \n",
    "    for chain_row in chain_configs.itertuples(index=False):\n",
    "        print(chain_row)\n",
    "        chain = chain_row.blockchain\n",
    "        block_time = chain_row.block_time_sec\n",
    "\n",
    "        mv_name = mv_row['mv_name']\n",
    "        print(f\"Processing chain: {chain} - {mv_name}\")\n",
    "\n",
    "        if mv_row['start_date'] != '':\n",
    "            mod_start_date = mv_row['start_date']\n",
    "        else:\n",
    "            mod_start_date = ''\n",
    "        \n",
    "        try:\n",
    "            print('create matview')\n",
    "            create_materialized_view(client, chain, mv_name, block_time = block_time)\n",
    "        except:\n",
    "            print('error')\n",
    "        try:\n",
    "            print('create backfill')\n",
    "            backfill_data(client, chain, mv_name, end_date = end_date, block_time = block_time, mod_start_date = mod_start_date, set_days_batch_size = set_days_batch_size)\n",
    "        except Exception as e:\n",
    "            print('An error occurred:')\n",
    "            print(str(e))\n",
    "            print('Traceback:')\n",
    "            print(traceback.format_exc())\n",
    "        \n",
    "    print(f\"Completed processing for {chain}\")\n",
    "\n",
    "print(\"All chains and views processed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_backfill_gaps(client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
