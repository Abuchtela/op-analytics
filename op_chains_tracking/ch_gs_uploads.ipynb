{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start ch uploads\n"
     ]
    }
   ],
   "source": [
    "print('start ch uploads')\n",
    "#Clickhouse db w/ Goldsky\n",
    "# https://clickhouse.com/docs/en/integrations/python\n",
    "\n",
    "import requests as r\n",
    "import pandas as pd\n",
    "import clickhouse_connect as cc\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import duneapi_utils as d\n",
    "import pandas_utils as p\n",
    "import clickhouse_utils as ch\n",
    "import csv_utils as cu\n",
    "import google_bq_utils as bqu\n",
    "sys.path.pop()\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "client = ch.connect_to_clickhouse_db() #Default is OPLabs DB\n",
    "# client.close()\n",
    "\n",
    "table_name = 'daily_aggegate_l2_chain_usage_goldsky'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_mappings_list = [\n",
    "    # {'schema_name': 'zora', 'display_name': 'Zora', 'has_blob_fields': False},\n",
    "    # {'schema_name': 'pgn', 'display_name': 'Public Goods Network', 'has_blob_fields': False},\n",
    "    # {'schema_name': 'base', 'display_name': 'Base', 'has_blob_fields': False},\n",
    "    {'schema_name': 'mode', 'display_name': 'Mode', 'has_blob_fields': False},\n",
    "    {'schema_name': 'metal', 'display_name': 'Metal', 'has_blob_fields': False},\n",
    "    {'schema_name': 'fraxtal', 'display_name': 'Fraxtal', 'has_blob_fields': True},\n",
    "    {'schema_name': 'bob', 'display_name': 'BOB (Build on Bitcoin)', 'has_blob_fields': False},\n",
    "    {'schema_name': 'cyber', 'display_name': 'Cyber', 'has_blob_fields': False},\n",
    "    # Add more mappings as needed\n",
    "]\n",
    "chain_mappings_dict = {item['schema_name']: item['display_name'] for item in chain_mappings_list}\n",
    "\n",
    "block_time_sec = 2\n",
    "\n",
    "trailing_days = 9999\n",
    "max_execution_secs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_directory = \"inputs/sql/\"\n",
    "\n",
    "query_names = [\n",
    "        # Must match the file name in inputs/sql\n",
    "        \"ch_template_alltime_chain_activity\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_template_alltime_chain_activity - cyber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_27325/740562861.py:20: DeprecationWarning: Bitwise inversion '~' on bool is deprecated. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.\n",
      "  if ~has_blob_fields:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table at: dune.oplabspbc.dataset_ch_template_alltime_chain_activity\n",
      "Response status code: 200\n",
      "Response content: b'{\"success\":true,\"table_name\":\"ch_template_alltime_chain_activity\"}'\n"
     ]
    }
   ],
   "source": [
    "for qn in query_names:\n",
    "        for mapping in chain_mappings_list:\n",
    "                chain_schema = mapping['schema_name']\n",
    "                display_name = mapping['display_name']\n",
    "                has_blob_fields = mapping['has_blob_fields']\n",
    "                # If we can do it programmatically from UI saved queries\n",
    "                # query = client.get_job(query_name)\n",
    "                # Read the SQL query from file\n",
    "                with open(os.path.join(sql_directory, f\"{qn}.sql\"), \"r\") as file:\n",
    "                        query = file.read()\n",
    "                print(qn + ' - ' + chain_schema)\n",
    "                dune_table_name = qn\n",
    "\n",
    "                #Pass in Params to the query\n",
    "                query = query.replace(\"@chain_db_name@\", chain_schema)\n",
    "                query = query.replace(\"@trailing_days@\", str(trailing_days))\n",
    "                query = query.replace(\"@block_time_sec@\", str(block_time_sec))\n",
    "                query = query.replace(\"@max_execution_secs@\", str(max_execution_secs))\n",
    "\n",
    "                if ~has_blob_fields:\n",
    "                        query = query.replace(\"receipt_l1_blob_base_fee_scalar\", 'cast(NULL as Nullable(Float64))')\n",
    "                        query = query.replace(\"receipt_l1_blob_base_fee\", 'cast(NULL as Nullable(Float64))')\n",
    "                        query = query.replace(\"receipt_l1_base_fee_scalar\", 'toInt64(NULL)')\n",
    "                # Execute the query\n",
    "                result_df = client.query_df(query)\n",
    "        #         # Write to csv\n",
    "        #         df.to_csv('outputs/chain_data/' + qn + '.csv', index=False)\n",
    "        #         # print(df.sample(5))\n",
    "        #         time.sleep(1)\n",
    "                \n",
    "                result_df['chain_raw'] = result_df['chain']\n",
    "                result_df['chain'] = result_df['chain'].replace(chain_mappings_dict)\n",
    "                unified_dfs.append(result_df)\n",
    "\n",
    "        write_df = pd.concat(unified_dfs)\n",
    "        write_df.to_csv('outputs/chain_data/' + dune_table_name + '.csv', index=False)\n",
    "        d.write_dune_api_from_pandas(write_df, dune_table_name,table_description = dune_table_name)\n",
    "        \n",
    "        # # # Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n",
      "Data loaded successfully to api_table_uploads.daily_aggegate_l2_chain_usage_goldsky\n"
     ]
    }
   ],
   "source": [
    "#BQ Upload\n",
    "time.sleep(1)\n",
    "bqu.write_df_to_bq_table(write_df, table_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
