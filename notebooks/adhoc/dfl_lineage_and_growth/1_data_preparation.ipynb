{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preparation.py\n",
    "\n",
    "\"\"\"\n",
    "Part 1: Data Preparation\n",
    "------------------------\n",
    "Pulls raw data (TVL, metadata) from DuckDB, merges protocol info with chain alignment,\n",
    "handles token mappings, and computes misrepresentation flags. Exports 'protocol_data_cleaned.csv'.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import urllib3\n",
    "import warnings\n",
    "\n",
    "from op_analytics.cli.subcommands.pulls.defillama.dataaccess import DefiLlama\n",
    "from op_analytics.coreutils.duckdb_inmem.client import init_client as init_duckdb\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize DuckDB client\n",
    "duckdb_client = init_client = init_duckdb()\n",
    "\n",
    "# Minimum date for data pull\n",
    "MINIMUM_DATE = \"2024-01-01\"\n",
    "\n",
    "# 1) Pull protocol TVL data from DuckDB\n",
    "view_tvl_data = DefiLlama.PROTOCOLS_TOKEN_TVL.read(min_date=MINIMUM_DATE)\n",
    "df_protocol_tvl_data = duckdb_client.client.sql(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        dt,\n",
    "        protocol_slug,\n",
    "        chain,\n",
    "        token,\n",
    "        app_token_tvl,\n",
    "        app_token_tvl_usd\n",
    "    FROM {view_tvl_data}\n",
    "    \"\"\"\n",
    ").to_df()\n",
    "\n",
    "# 2) Pull protocol metadata from DuckDB\n",
    "view_meta_data = DefiLlama.PROTOCOLS_METADATA.read(min_date=MINIMUM_DATE)\n",
    "df_protocol_metadata = duckdb_client.client.sql(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        protocol_name,\n",
    "        protocol_slug,\n",
    "        protocol_category,\n",
    "        parent_protocol,\n",
    "        misrepresented_tokens\n",
    "    FROM {view_meta_data}\n",
    "    \"\"\"\n",
    ").to_df()\n",
    "\n",
    "# Convert misrepresented_tokens to int\n",
    "df_protocol_metadata[\"misrepresented_tokens\"] = df_protocol_metadata[\"misrepresented_tokens\"].map(\n",
    "    {\"True\": 1, \"False\": 0}\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# 3) Token-level mapping stored as a list of dicts\n",
    "source_tokens_data = [\n",
    "    {\"token\":\"WEETH\",\"project\":\"Ether-fi\",\"source_protocol\":\"ether-fi\"},\n",
    "    {\"token\":\"GRT\",\"project\":\"The Graph\",\"source_protocol\":\"the-graph\"},\n",
    "    {\"token\":\"PT-SUSDE-27MAR2025\",\"project\":\"Pendle\",\"source_protocol\":\"pendle\"},\n",
    "    {\"token\":\"EURC\",\"project\":\"Circle\",\"source_protocol\":\"circle\"},\n",
    "    {\"token\":\"FBOMB\",\"project\":\"Millennium Club\",\"source_protocol\":\"millenium-club\"},\n",
    "    {\"token\":\"WETH-USDC-GMX-V2\",\"project\":\"GMX\",\"source_protocol\":\"gmx\"},\n",
    "    {\"token\":\"USD0++\",\"project\":\"Usual\",\"source_protocol\":\"usual-money\"},\n",
    "    {\"token\":\"WSTETH\",\"project\":\"Lido\",\"source_protocol\":\"lido\"},\n",
    "    {\"token\":\"MGLP\",\"project\":\"Abracadabra Money\",\"source_protocol\":\"abracadabra\"},\n",
    "    {\"token\":\"USDT\",\"project\":\"Tether\",\"source_protocol\":\"tether\"},\n",
    "    {\"token\":\"AIXBT\",\"project\":\"Virtuals Protocol\",\"source_protocol\":\"virtuals-protocol\"},\n",
    "    {\"token\":\"VAWSTETH\",\"project\":\"Metronome\",\"source_protocol\":\"metronome\"},\n",
    "    {\"token\":\"MBTC\",\"project\":\"Merlin\",\"source_protocol\":\"merlin\"},\n",
    "    {\"token\":\"FRAX\",\"project\":\"Frax Finance\",\"source_protocol\":\"frax-finance\"},\n",
    "    {\"token\":\"AETHWSTETH\",\"project\":\"Ankr\",\"source_protocol\":\"ankr\"},\n",
    "    {\"token\":\"USX\",\"project\":\"dForce\",\"source_protocol\":\"dforce\"},\n",
    "    {\"token\":\"BEAN\",\"project\":\"Beanstalk\",\"source_protocol\":\"beanstalk\"},\n",
    "    {\"token\":\"PENDLE\",\"project\":\"Pendle\",\"source_protocol\":\"pendle\"},\n",
    "    {\"token\":\"GLP\",\"project\":\"GMX\",\"source_protocol\":\"gmx\"},\n",
    "    {\"token\":\"OP\",\"project\":\"Optimism\",\"source_protocol\":\"optimism\"},\n",
    "    {\"token\":\"WSUPEROETHB\",\"project\":\"Origin Protocol\",\"source_protocol\":\"origin-defi\"},\n",
    "    {\"token\":\"WETH\",\"project\":\"Ethereum\",\"source_protocol\":\"ethereum\"},\n",
    "    {\"token\":\"SOLVBTC.BBN\",\"project\":\"Solv\",\"source_protocol\":\"solv-protocol\"},\n",
    "    {\"token\":\"LPT\",\"project\":\"Livepeer\",\"source_protocol\":\"livepeer\"},\n",
    "    {\"token\":\"MIM\",\"project\":\"Abracadabra Money\",\"source_protocol\":\"abracadabra\"},\n",
    "    {\"token\":\"LOTUS\",\"project\":\"Lotus\",\"source_protocol\":\"lotus\"},\n",
    "    {\"token\":\"EBTC\",\"project\":\"eBTC\",\"source_protocol\":\"ebtc-protocol\"},\n",
    "    {\"token\":\"SEAM\",\"project\":\"Seamless Protocol\",\"source_protocol\":\"seamless-protocol\"},\n",
    "    {\"token\":\"SWETH\",\"project\":\"Swell Network\",\"source_protocol\":\"swell\"},\n",
    "    {\"token\":\"PAXG\",\"project\":\"Paxos\",\"source_protocol\":\"paxos-gold\"},\n",
    "    {\"token\":\"ARB\",\"project\":\"Arbitrum\",\"source_protocol\":\"abritrum\"},\n",
    "    {\"token\":\"SUPEROETHB\",\"project\":\"Origin Protocol\",\"source_protocol\":\"origin-defi\"},\n",
    "    {\"token\":\"NORMIE\",\"project\":\"Normie\",\"source_protocol\":\"normie\"},\n",
    "    {\"token\":\"ETHX\",\"project\":\"Stader Labs\",\"source_protocol\":\"stader\"},\n",
    "    {\"token\":\"LQDR\",\"project\":\"Abacus\",\"source_protocol\":\"abacus\"},\n",
    "    {\"token\":\"GMX\",\"project\":\"GMX\",\"source_protocol\":\"gms\"},\n",
    "    {\"token\":\"EETH\",\"project\":\"Ether-fi\",\"source_protocol\":\"ether-fi\"},\n",
    "    {\"token\":\"SUSD\",\"project\":\"Synthetix\",\"source_protocol\":\"synthetix\"},\n",
    "    {\"token\":\"PT-SUSDE-26DEC2024\",\"project\":\"Pendle\",\"source_protocol\":\"pendle\"},\n",
    "    {\"token\":\"SOLVBTC\",\"project\":\"Solv\",\"source_protocol\":\"solv-protocol\"},\n",
    "    {\"token\":\"DEGEN\",\"project\":\"Degen\",\"source_protocol\":\"degen\"},\n",
    "    {\"token\":\"EUSD\",\"project\":\"Reserve Protocol\",\"source_protocol\":\"reserve-protocol\"},\n",
    "    {\"token\":\"VELO\",\"project\":\"Velodrome Finance\",\"source_protocol\":\"velodrome\"},\n",
    "    {\"token\":\"BPT-ETHTRI\",\"project\":\"Balancer\",\"source_protocol\":\"balancer\"},\n",
    "    {\"token\":\"USDBC\",\"project\":\"Circle\",\"source_protocol\":\"circle\"},\n",
    "    {\"token\":\"GRAIL\",\"project\":\"Camelot\",\"source_protocol\":\"camelot\"},\n",
    "    {\"token\":\"USDC+\",\"project\":\"Overnight Finance\",\"source_protocol\":\"overnight-finance\"},\n",
    "    {\"token\":\"AAVE\",\"project\":\"Aave\",\"source_protocol\":\"aave\"},\n",
    "    {\"token\":\"RDNT\",\"project\":\"Radiant Capital\",\"source_protocol\":\"radiant\"},\n",
    "    {\"token\":\"DEXE\",\"project\":\"Dexe.network\",\"source_protocol\":\"dexe\"},\n",
    "    {\"token\":\"AMP\",\"project\":\"Amp\",\"source_protocol\":\"amp\"},\n",
    "    {\"token\":\"RNDR\",\"project\":\"Render Network\",\"source_protocol\":\"render\"},\n",
    "    {\"token\":\"ETH\",\"project\":\"Ethereum\",\"source_protocol\":\"ethereum\"},\n",
    "    {\"token\":\"WSOL\",\"project\":\"Solana\",\"source_protocol\":\"solana\"},\n",
    "    {\"token\":\"STETH\",\"project\":\"Lido\",\"source_protocol\":\"lido\"},\n",
    "    {\"token\":\"ALUSD\",\"project\":\"Alchemix\",\"source_protocol\":\"alchemix\"},\n",
    "    {\"token\":\"USDC.E\",\"project\":\"Circle\",\"source_protocol\":\"circle\"},\n",
    "    {\"token\":\"RETH\",\"project\":\"Rocket Pool\",\"source_protocol\":\"rocket-pool\"},\n",
    "    {\"token\":\"METH\",\"project\":\"Mantle\",\"source_protocol\":\"mantle-restaking\"},\n",
    "    {\"token\":\"UNI\",\"project\":\"Uniswap\",\"source_protocol\":\"uniswap\"},\n",
    "    {\"token\":\"WRSETH/WETH\",\"project\":\"Balancer\",\"source_protocol\":\"balancer\"},\n",
    "    {\"token\":\"TBTC\",\"project\":\"Threshold Network\",\"source_protocol\":\"threshold-network\"},\n",
    "    {\"token\":\"BPT-RETH-ETH\",\"project\":\"Balancer\",\"source_protocol\":\"balancer\"},\n",
    "    {\"token\":\"CBBTC\",\"project\":\"Coinbase\",\"source_protocol\":\"coinbase\"},\n",
    "    {\"token\":\"UNIBTC\",\"project\":\"Bedrock\",\"source_protocol\":\"bedrock\"},\n",
    "    {\"token\":\"HEGIC\",\"project\":\"Hegic\",\"source_protocol\":\"hegic\"},\n",
    "    {\"token\":\"SUSDE\",\"project\":\"Ethena\",\"source_protocol\":\"ethena\"},\n",
    "    {\"token\":\"DAI\",\"project\":\"MakerDAO\",\"source_protocol\":\"maker\"},\n",
    "    {\"token\":\"VIRTUAL\",\"project\":\"Virtuals Protocol\",\"source_protocol\":\"virtuals-protocol\"},\n",
    "    {\"token\":\"USDM\",\"project\":\"Mountain Protocol\",\"source_protocol\":\"mountain-protocol\"},\n",
    "    {\"token\":\"PZETH\",\"project\":\"Pendle\",\"source_protocol\":\"pendle\"},\n",
    "    {\"token\":\"MSTETH\",\"project\":\"Magpie\",\"source_protocol\":\"magpie-ecosystem\"},\n",
    "    {\"token\":\"WBTC-WBTC-GMX-V2\",\"project\":\"GMX\",\"source_protocol\":\"gmx\"},\n",
    "    {\"token\":\"D2\",\"project\":\"D2 Finance\",\"source_protocol\":\"d2-finance\"},\n",
    "    {\"token\":\"CRV\",\"project\":\"Curve Finance\",\"source_protocol\":\"curve-finance\"},\n",
    "    {\"token\":\"MATIC\",\"project\":\"Polygon\",\"source_protocol\":\"polygon\"},\n",
    "    {\"token\":\"LFBTC-AVALON-ETH\",\"project\":\"Avalon Finance\",\"source_protocol\":\"avalon-labs\"},\n",
    "    {\"token\":\"EGETH\",\"project\":\"Magpie\",\"source_protocol\":\"magpie-ecosystem\"},\n",
    "    {\"token\":\"LUNA\",\"project\":\"Terra\",\"source_protocol\":\"terra\"},\n",
    "    {\"token\":\"AERO\",\"project\":\"Aerodrome Finance\",\"source_protocol\":\"aerodrome\"},\n",
    "    {\"token\":\"CDXUSD\",\"project\":\"cod3x\",\"source_protocol\":\"cod3x\"},\n",
    "    {\"token\":\"OGN\",\"project\":\"Origin Protocol\",\"source_protocol\":\"origin-defi\"},\n",
    "    {\"token\":\"BSDETH\",\"project\":\"Reserve Protocol\",\"source_protocol\":\"reserve-protocol\"},\n",
    "    {\"token\":\"PENDLE-LPT\",\"project\":\"Pendle\",\"source_protocol\":\"pendle\"},\n",
    "    {\"token\":\"WETH-WETH-GMX-V2\",\"project\":\"GMX\",\"source_protocol\":\"gmx\"},\n",
    "    {\"token\":\"EPENDLE\",\"project\":\"Equilibria Finance\",\"source_protocol\":\"equilibria\"},\n",
    "    {\"token\":\"STAR\",\"project\":\"Preon\",\"source_protocol\":\"preon\"},\n",
    "    {\"token\":\"MPENDLE\",\"project\":\"Magpie\",\"source_protocol\":\"magpie-ecosystem\"},\n",
    "    {\"token\":\"PUMPBTC\",\"project\":\"Pump BTC\",\"source_protocol\":\"pumpbtc\"},\n",
    "    {\"token\":\"WBTC\",\"project\":\"Wrapped Bitcoin\",\"source_protocol\":\"wrapped-bitcoin\"},\n",
    "    {\"token\":\"XAUT\",\"project\":\"Tether Gold\",\"source_protocol\":\"tether-gold\"},\n",
    "    {\"token\":\"RSETH\",\"project\":\"KelpDAO\",\"source_protocol\":\"kelp-dao\"},\n",
    "    {\"token\":\"USDC\",\"project\":\"Circle\",\"source_protocol\":\"circle\"},\n",
    "    {\"token\":\"USDZ\",\"project\":\"Anzen\",\"source_protocol\":\"anzen-finance\"},\n",
    "    {\"token\":\"BRETT\",\"project\":\"Brett\",\"source_protocol\":\"brett\"},\n",
    "    {\"token\":\"(=ↀΩↀ=)\",\"project\":\"Nekodex\",\"source_protocol\":\"nekodex\"},\n",
    "    {\"token\":\"OUSG\",\"project\":\"Ondo Finance\",\"source_protocol\":\"ondo-finance\"},\n",
    "    {\"token\":\"CBETH\",\"project\":\"Coinbase\",\"source_protocol\":\"coinbase\"},\n",
    "    {\"token\":\"MAI\",\"project\":\"Mai Finance\",\"source_protocol\":\"mai-finance\"},\n",
    "    {\"token\":\"LBTC\",\"project\":\"Lombard\",\"source_protocol\":\"lombard-finance\"},\n",
    "    {\"token\":\"BALD\",\"project\":\"Bald\",\"source_protocol\":\"balancer\"},\n",
    "    {\"token\":\"USDE\",\"project\":\"Ethena\",\"source_protocol\":\"ethena\"},\n",
    "    {\"token\":\"FSGLP\",\"project\":\"GMX\",\"source_protocol\":\"gmx\"},\n",
    "    {\"token\":\"USYC\",\"project\":\"Hashnote\",\"source_protocol\":\"hashnote-usyc\"},\n",
    "    {\"token\":\"USDY\",\"project\":\"Ondo Finance\",\"source_protocol\":\"ondo-finance\"},\n",
    "    {\"token\":\"WBTC-USDC-GMX-V2\",\"project\":\"GMX\",\"source_protocol\":\"gmx\"},\n",
    "    {\"token\":\"ENA\",\"project\":\"Ethena\",\"source_protocol\":\"ethena\"},\n",
    "    {\"token\":\"WEETHS\",\"project\":\"Ether-fi\",\"source_protocol\":\"ether-fi\"},\n",
    "    {\"token\":\"WRSETH\",\"project\":\"KelpDAO\",\"source_protocol\":\"kelp-dao\"},\n",
    "    {\"token\":\"LINK\",\"project\":\"Chainlink\",\"source_protocol\":\"chainlink\"},\n",
    "    {\"token\":\"DOLA\",\"project\":\"Inverse Finance\",\"source_protocol\":\"inverse-finance\"},\n",
    "    {\"token\":\"SPEC\",\"project\":\"Spectral Labs\",\"source_protocol\":\"spectral-labs\"},\n",
    "    {\"token\":\"WEETH.BASE\",\"project\":\"Ether-fi\",\"source_protocol\":\"ether-fi\"},\n",
    "    {\"token\":\"TWETH\",\"project\":\"Twittereum\",\"source_protocol\":\"twittereum\"},\n",
    "    {\"token\":\"SFRXETH\",\"project\":\"Frax Finance\",\"source_protocol\":\"frax-finance\"},\n",
    "    {\"token\":\"WBETH\",\"project\":\"Binance\",\"source_protocol\":\"binance\"},\n",
    "    {\"token\":\"EZETH\",\"project\":\"Renzo\",\"source_protocol\":\"renzo\"},\n",
    "    {\"token\":\"USD+\",\"project\":\"Overnight Finance\",\"source_protocol\":\"overnight-finance\"},\n",
    "    {\"token\":\"SNX\",\"project\":\"Synthetix\",\"source_protocol\":\"synthetix\"}\n",
    "]\n",
    "df_source_tokens = pd.DataFrame(source_tokens_data)\n",
    "\n",
    "# 4) Extra mappings and helper data\n",
    "UNWANTED_PATTERNS = [\n",
    "    \"-borrowed\", \"-vesting\", \"-staking\", \"-pool2\", \"-treasury\", \"-cex\",\n",
    "    \"^treasury$\", \"^borrowed$\", \"^staking$\", \"^pool2$\", \"polygon-bridge-&-staking\", \".*-cex$\"\n",
    "]\n",
    "UNWANTED_CATEGORIES = [\"CEX\", \"Chain\"]\n",
    "\n",
    "chain_alignment_map = {\n",
    "    \"Metis\": \"OP Stack Fork\",\n",
    "    \"Blast\": \"OP Stack Fork\",\n",
    "    \"Mantle\": \"OP Stack Fork\",\n",
    "    \"Zircuit\": \"OP Stack Fork\",\n",
    "    \"RSS3\": \"OP Stack Fork\",\n",
    "    \"Rollux\": \"OP Stack Fork\",\n",
    "    \"Ancient8\": \"OP Stack Fork\",\n",
    "    \"Manta\": \"OP Stack Fork\",\n",
    "    \"Cyber\": \"OP Chain\",\n",
    "    \"Mint\": \"OP Chain\",\n",
    "    \"Ham\": \"OP Chain\",\n",
    "    \"Polynomial\": \"OP Chain\",\n",
    "    \"Lisk\": \"OP Chain\",\n",
    "    \"BOB\": \"OP Chain\",\n",
    "    \"Mode\": \"OP Chain\",\n",
    "    \"World Chain\": \"OP Chain\",\n",
    "    \"Base\": \"OP Chain\",\n",
    "    \"Kroma\": \"OP Chain\",\n",
    "    \"Boba\": \"OP Chain\",\n",
    "    \"Fraxtal\": \"OP Chain\",\n",
    "    \"Optimism\": \"OP Chain\",\n",
    "    \"Shape\": \"OP Chain\",\n",
    "    \"Zora\": \"OP Chain\"\n",
    "}\n",
    "\n",
    "token_category_data = [\n",
    "    {\"token\": \"ETH\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"WETH\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"SOL\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"WBTC\", \"token_category\": \"Wrapped Assets\"}\n",
    "]\n",
    "\n",
    "protocol_category_map = {\n",
    "    \"Dexes\": \"Trading\",\n",
    "    \"Liquidity manager\": \"Yield\",\n",
    "    \"Derivatives\": \"Derivatives\",\n",
    "    \"Yield Aggregator\": \"Yield\",\n",
    "    \"Indexes\": \"Yield\",\n",
    "    \"Bridge\": \"Trading\",\n",
    "    \"Leveraged Farming\": \"Yield\",\n",
    "    \"Cross Chain\": \"Trading\",\n",
    "    \"CDP\": \"Lending\",\n",
    "    \"Farm\": \"Yield\",\n",
    "    \"Options\": \"Trading\",\n",
    "    \"DCA Tools\": \"Trading\",\n",
    "    \"Services\": \"TradFi/Fintech\",\n",
    "    \"Chain\": \"TradFi/Fintech\",\n",
    "    \"Privacy\": \"TradFi/Fintech\",\n",
    "    \"RWA\": \"TradFi/Fintech\",\n",
    "    \"Payments\": \"TradFi/Fintech\",\n",
    "    \"Launchpad\": \"TradFi/Fintech\",\n",
    "    \"Synthetics\": \"Derivatives\",\n",
    "    \"SoFi\": \"TradFi/Fintech\",\n",
    "    \"Prediction Market\": \"Trading\",\n",
    "    \"Token Locker\": \"Yield\",\n",
    "    \"Yield Lottery\": \"Yield\",\n",
    "    \"Algo-Stables\": \"Stablecoins\",\n",
    "    \"DEX Aggregator\": \"Trading\",\n",
    "    \"Liquid Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Governance Incentives\": \"Yield\",\n",
    "    \"Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Liquid Staking\": \"Liquid Staking\",\n",
    "    \"Uncollateralized Lending\": \"Lending\",\n",
    "    \"Managed Token Pools\": \"Trading\",\n",
    "    \"Insurance\": \"TradFi/Fintech\",\n",
    "    \"NFT Marketplace\": \"Trading\",\n",
    "    \"NFT Lending\": \"Lending\",\n",
    "    \"Options Vault\": \"Trading\",\n",
    "    \"NftFi\": \"Trading\",\n",
    "    \"Basis Trading\": \"Trading\",\n",
    "    \"Bug Bounty\": \"TradFi/Fintech\",\n",
    "    \"OTC Marketplace\": \"Trading\",\n",
    "    \"Reserve Currency\": \"Stablecoins\",\n",
    "    \"Gaming\": \"Other\",\n",
    "    \"AI Agents\": \"TradFi/Fintech\",\n",
    "    \"Treasury Manager\": \"TradFi/Fintech\",\n",
    "    \"CDP Manager\": \"Lending\",\n",
    "    \"Decentralized Stablecoin\": \"Stablecoins\",\n",
    "    \"Restaked BTC\": \"Restaking/Liquid Restaking\",\n",
    "    \"RWA Lending\": \"Lending\",\n",
    "    \"Staking Pool\": \"Staking/Liquid Staking\",\n",
    "    \"CeDeFi\": \"TradFi/Fintech\",\n",
    "    \"Staking\": \"Staking/Liquid Staking\",\n",
    "    \"Oracle\": \"Other\",\n",
    "    \"Ponzi\": \"Other\",\n",
    "    \"Anchor BTC\": \"Other\",\n",
    "    \"Decentralized BTC\": \"Other\",\n",
    "    \"CEX\": \"Other\",\n",
    "    \"Lending\": \"Lending\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cleaned protocol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Merge metadata + TVL\n",
    "df_merged = pd.merge(\n",
    "    df_protocol_metadata.drop_duplicates(),\n",
    "    df_protocol_tvl_data.drop_duplicates(),\n",
    "    on=\"protocol_slug\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 6) Merge chain alignment info\n",
    "df_chain_alignment = pd.DataFrame(list(chain_alignment_map.items()), columns=[\"chain\", \"alignment\"])\n",
    "df_merged = pd.merge(df_merged, df_chain_alignment, on=\"chain\", how=\"left\")\n",
    "df_merged[\"alignment\"] = df_merged[\"alignment\"].fillna(\"Other\")\n",
    "\n",
    "# 7) Merge token category info\n",
    "df_token_lookup = pd.DataFrame(token_category_data)\n",
    "df_token_lookup[\"token\"] = df_token_lookup[\"token\"].str.upper()\n",
    "df_merged[\"token\"] = df_merged[\"token\"].str.upper()\n",
    "df_merged = pd.merge(df_merged, df_token_lookup, on=\"token\", how=\"left\")\n",
    "df_merged[\"token_category\"] = df_merged[\"token_category\"].fillna(\"Other\")\n",
    "\n",
    "# 8) Compute chain-level misrepresentation\n",
    "def calculate_misrepresentation_flags(df_input):\n",
    "    ref_date = df_input[\"dt\"].max() - pd.Timedelta(days=1)\n",
    "    df_flags = (\n",
    "        df_input[df_input.dt == ref_date]\n",
    "        [[\"protocol_slug\", \"chain\", \"misrepresented_tokens\", \"token\"]]\n",
    "        .groupby([\"protocol_slug\", \"chain\", \"misrepresented_tokens\"])\n",
    "        .agg(\n",
    "            token_count=(\"token\", \"nunique\"),\n",
    "            has_usdt=(\"token\", lambda x: 1 if \"USDT\" in x.values else 0)\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_flags[\"chain_misrepresented_tokens\"] = (\n",
    "        (df_flags[\"misrepresented_tokens\"] == 1)\n",
    "        & (df_flags[\"token_count\"] == 1)\n",
    "        & (df_flags[\"has_usdt\"] == 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    return df_flags\n",
    "\n",
    "df_chain_misrep = calculate_misrepresentation_flags(df_merged)\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    df_chain_misrep[[\"protocol_slug\", \"chain\", \"chain_misrepresented_tokens\"]],\n",
    "    on=[\"protocol_slug\", \"chain\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_merged[\"dt\"] = pd.to_datetime(df_merged[\"dt\"])\n",
    "df_merged[\"parent_protocol\"] = df_merged[\"parent_protocol\"].astype(str).str.replace(\"parent#\", \"\", regex=False)\n",
    "\n",
    "# 9) If chain-level misrep is true, override token category\n",
    "df_merged[\"token_category_misrep\"] = np.where(\n",
    "    (df_merged[\"chain_misrepresented_tokens\"] == 1),\n",
    "    \"Misrepresented TVL\",\n",
    "    df_merged[\"token_category\"]\n",
    ")\n",
    "\n",
    "# 10) Map protocol categories to simpler classification\n",
    "df_merged[\"protocol_category_mapped\"] = df_merged[\"protocol_category\"].map(protocol_category_map, na_action=\"ignore\")\n",
    "df_merged.loc[df_merged[\"protocol_category_mapped\"].isna(), \"protocol_category_mapped\"] = df_merged[\"protocol_category\"]\n",
    "\n",
    "# 11) Merge in source token info\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    df_source_tokens[[\"token\", \"project\", \"source_protocol\"]].drop_duplicates(),\n",
    "    on=\"token\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 12) Export final CSV\n",
    "cleaned_export_name = \"protocol_data_cleaned.csv\"\n",
    "df_merged.to_csv(cleaned_export_name, index=False)\n",
    "print(f\"Exported {df_merged.shape[0]} rows to {cleaned_export_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering & Aggregation for the Growth measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_main_cleaned with shape (28928746, 17)\n",
      "df_postfilter shape: (5111464, 17)\n",
      "df_rollup shape: (289429, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 916/916 [00:07<00:00, 121.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final df_final_tvl shape: (129791, 6)\n",
      "Excluded 467 protocols due to filters or low TVL.\n",
      "Saved final_tvl_aggregate.csv.\n"
     ]
    }
   ],
   "source": [
    "# data_filter_aggregate.py\n",
    "\n",
    "\"\"\"\n",
    "Part 2: Data Filtering & Aggregation\n",
    "------------------------------------\n",
    "Loads 'protocol_data_cleaned.csv', applies pattern/category filters, \n",
    "excludes protocols under 500k TVL in the final week, and aggregates \n",
    "cross-chain TVL by parent_protocol. Exports 'final_tvl_aggregate.csv'.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# File path to the cleaned data\n",
    "CLEANED_DATA_PATH = \"protocol_data_cleaned.csv\"\n",
    "\n",
    "ANALYSIS_START = \"2024-01-01\"\n",
    "ANALYSIS_END = \"2024-12-01\"\n",
    "\n",
    "# Patterns and categories from data_preparation.py\n",
    "UNWANTED_PATTERNS = [\n",
    "    \"-borrowed\", \"-vesting\", \"-staking\", \"-pool2\", \"-treasury\", \"-cex\",\n",
    "    \"^treasury$\", \"^borrowed$\", \"^staking$\", \"^pool2$\", \"polygon-bridge-&-staking\", \".*-cex$\"\n",
    "]\n",
    "UNWANTED_CATEGORIES = [\"CEX\", \"Chain\"]\n",
    "\n",
    "# Suppose you unify or map your protocol categories:\n",
    "SIMPLE_CATEGORY_MAP = {\n",
    "    # Core categories from the original snippet\n",
    "    \"Dexes\": \"Trading\",\n",
    "    \"Liquidity manager\": \"Yield\",\n",
    "    \"Derivatives\": \"Derivatives\",\n",
    "    \"CEX\": \"Other\",\n",
    "    \"Staking\": \"Staking/Liquid Staking\",\n",
    "    \"Farm\": \"Yield\",\n",
    "    \"CDP\": \"Lending\",\n",
    "    \"Bridge\": \"Trading\",\n",
    "    \"Chain\": \"Other\",\n",
    "    \"Lending\": \"Lending\",\n",
    "    \"Cross Chain\": \"Trading\",\n",
    "    \"Algo-Stables\": \"Stablecoins\",\n",
    "    \"Synthetics\": \"Derivatives\",\n",
    "    \"Stablecoins\": \"Stablecoins\",\n",
    "    \"Yield\": \"Yield\",\n",
    "    \"Trading\": \"Trading\",\n",
    "    \"TradFi/Fintech\": \"TradFi/Fintech\",\n",
    "    \"Other\": \"Other\",\n",
    "    \"Restaking/Liquid Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Liquid Staking\": \"Liquid Staking\",\n",
    "    \"Staking/Liquid Staking\": \"Staking/Liquid Staking\",\n",
    "\n",
    "    # Additional sub-categories appearing in df_tvl_agg/final_growth_df\n",
    "    \"Yield Aggregator\": \"Yield\",\n",
    "    \"RWA\": \"TradFi/Fintech\",\n",
    "    \"Indexes\": \"Yield\",\n",
    "    \"Liquid Restaking\": \"Restaking/Liquid Restaking\",  # same bucket as above\n",
    "    \"Insurance\": \"TradFi/Fintech\",\n",
    "    \"NFT Lending\": \"Lending\",\n",
    "    \"Options\": \"Trading\",\n",
    "    \"Privacy\": \"TradFi/Fintech\",\n",
    "    \"Leveraged Farming\": \"Yield\",\n",
    "    \"Prediction Market\": \"Trading\",\n",
    "    \"Payments\": \"TradFi/Fintech\",\n",
    "    \"Uncollateralized Lending\": \"Lending\",\n",
    "    \"NFT Marketplace\": \"Trading\",\n",
    "    \"Launchpad\": \"TradFi/Fintech\",\n",
    "    \"Token Locker\": \"Yield\",\n",
    "    \"Restaking\": \"Restaking/Liquid Restaking\",         # same bucket as above\n",
    "    \"Basis Trading\": \"Trading\",\n",
    "    \"DEX Aggregator\": \"Trading\",\n",
    "    \"Options Vault\": \"Trading\",\n",
    "    \"CDP Manager\": \"Lending\",\n",
    "    \"Reserve Currency\": \"Stablecoins\",\n",
    "    \"Managed Token Pools\": \"Trading\",\n",
    "    \"Yield Lottery\": \"Yield\",\n",
    "    \"Liquidity Automation\": \"Yield\",\n",
    "    \"RWA Lending\": \"Lending\",\n",
    "    \"Bug Bounty\": \"TradFi/Fintech\",\n",
    "    \"Governance Incentives\": \"Yield\",\n",
    "    \"Treasury Manager\": \"TradFi/Fintech\",\n",
    "    \"Decentralized BTC\": \"Other\",\n",
    "    \"AI Agents\": \"TradFi/Fintech\",\n",
    "    \"OTC Marketplace\": \"Trading\",\n",
    "    \"SoFi\": \"TradFi/Fintech\",\n",
    "    \"Anchor BTC\": \"Other\",\n",
    "    \"Staking Pool\": \"Staking/Liquid Staking\"\n",
    "}\n",
    "\n",
    "def does_match_unwanted_pattern(s: str) -> bool:\n",
    "    \"\"\"Check if a string hits any of the undesired patterns.\"\"\"\n",
    "    return any(re.search(pattern, s, re.IGNORECASE) for pattern in UNWANTED_PATTERNS)\n",
    "\n",
    "def exclude_small_tvl_protocols(df: pd.DataFrame, analysis_start: str, analysis_end: str, min_tvl: int = 500000):\n",
    "    \"\"\"\n",
    "    Removes protocols that remain under 500k TVL in the last 7 days\n",
    "    of the given analysis period.\n",
    "    \"\"\"\n",
    "    df[\"dt\"] = pd.to_datetime(df[\"dt\"], errors=\"coerce\")\n",
    "    start = pd.to_datetime(analysis_start)\n",
    "    end = pd.to_datetime(analysis_end)\n",
    "    protocol_names = df[\"protocol_name\"].unique()\n",
    "\n",
    "    kept_records = []\n",
    "    excluded_list = []\n",
    "\n",
    "    for proto in tqdm(protocol_names):\n",
    "        df_single = df[df[\"protocol_name\"] == proto].copy()\n",
    "        if df_single.empty:\n",
    "            excluded_list.append({\"protocol\": proto, \"reason\": \"No data\"})\n",
    "            continue\n",
    "\n",
    "        df_single = df_single[(df_single[\"dt\"] >= start) & (df_single[\"dt\"] <= end)]\n",
    "        if df_single.empty:\n",
    "            excluded_list.append({\"protocol\": proto, \"reason\": \"No data in period\"})\n",
    "            continue\n",
    "\n",
    "        df_single.set_index(\"dt\", inplace=True)\n",
    "        daily_tvl_series = df_single[\"app_token_tvl_usd\"].resample(\"D\").last()\n",
    "        last_week = daily_tvl_series.last(\"7D\")\n",
    "\n",
    "        if last_week.mean() < min_tvl:\n",
    "            excluded_list.append({\"protocol\": proto, \"reason\": \"<500k TVL last 7 days\"})\n",
    "            continue\n",
    "\n",
    "        kept_records.append(df_single.reset_index())\n",
    "\n",
    "    if kept_records:\n",
    "        final_filtered_df = pd.concat(kept_records, ignore_index=True)\n",
    "    else:\n",
    "        final_filtered_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    return final_filtered_df, excluded_list\n",
    "\n",
    "# 1. Load cleaned data\n",
    "df_main_cleaned = pd.read_csv(CLEANED_DATA_PATH)\n",
    "print(f\"Loaded df_main_cleaned with shape {df_main_cleaned.shape}\")\n",
    "\n",
    "# 2. Convert dt to datetime\n",
    "df_main_cleaned[\"dt\"] = pd.to_datetime(df_main_cleaned[\"dt\"], errors=\"coerce\")\n",
    "df_main_cleaned[\"chain\"] = df_main_cleaned[\"chain\"].astype(str)\n",
    "\n",
    "# 3. Map protocol_category to a simpler classification\n",
    "df_main_cleaned[\"protocol_category_mapped\"] = (\n",
    "    df_main_cleaned[\"protocol_category\"].map(SIMPLE_CATEGORY_MAP, na_action=\"ignore\")\n",
    ")\n",
    "df_main_cleaned.loc[\n",
    "    df_main_cleaned[\"protocol_category_mapped\"].isna(), \n",
    "    \"protocol_category_mapped\"\n",
    "] = df_main_cleaned[\"protocol_category\"]\n",
    "\n",
    "# 4. Create a helper DataFrame to mark undesired protocols\n",
    "df_chain_proto_helper = df_main_cleaned[[\"chain\", \"protocol_slug\", \"protocol_category\"]].drop_duplicates()\n",
    "df_chain_proto_helper[\"unwanted_mark\"] = (\n",
    "    df_chain_proto_helper[\"chain\"].apply(does_match_unwanted_pattern)\n",
    "    | df_chain_proto_helper[\"protocol_slug\"].str.endswith(\"-cex\")\n",
    "    | df_chain_proto_helper[\"protocol_slug\"].eq(\"polygon-bridge-&-staking\")\n",
    "    | df_chain_proto_helper[\"protocol_category\"].isin(UNWANTED_CATEGORIES)\n",
    ").astype(int)\n",
    "\n",
    "# 5. Example chain selection logic: keep only Ethereum \n",
    "df_chain_proto_helper[\"chain_selected\"] = (df_chain_proto_helper[\"chain\"] == \"Ethereum\").astype(int)\n",
    "\n",
    "# 6. Final filter\n",
    "final_chain_mask = (\n",
    "    (df_chain_proto_helper[\"unwanted_mark\"] == 0)\n",
    "    & (df_chain_proto_helper[\"chain_selected\"] == 1)\n",
    ")\n",
    "\n",
    "# 7. Apply the filter\n",
    "df_postfilter = pd.merge(\n",
    "    df_main_cleaned,\n",
    "    df_chain_proto_helper[final_chain_mask][[\"chain\",\"protocol_slug\",\"protocol_category\"]],\n",
    "    on=[\"chain\",\"protocol_slug\",\"protocol_category\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "print(f\"df_postfilter shape: {df_postfilter.shape}\")\n",
    "\n",
    "# 8. Aggregate by (parent_protocol, dt) => cross-chain TVL\n",
    "df_rollup = (\n",
    "    df_postfilter.groupby([\"parent_protocol\",\"dt\"], as_index=False)\n",
    "    .agg(\n",
    "        app_token_tvl_usd=(\"app_token_tvl_usd\",\"sum\"),\n",
    "        app_token_tvl=(\"app_token_tvl\",\"sum\"),\n",
    "        chains_count=(\"chain\",\"nunique\"),\n",
    "        protocol_category=(\"protocol_category_mapped\", lambda x: x.mode()[0] if not x.mode().empty else x.iloc[0])\n",
    "    )\n",
    "    .sort_values(by=\"app_token_tvl_usd\", ascending=False)\n",
    ")\n",
    "df_rollup.rename(columns={\"parent_protocol\":\"protocol_name\"}, inplace=True)\n",
    "print(f\"df_rollup shape: {df_rollup.shape}\")\n",
    "\n",
    "# 9. Exclude protocols < 500k TVL in final week\n",
    "df_final_tvl, excluded_list = exclude_small_tvl_protocols(\n",
    "    df=df_rollup,\n",
    "    analysis_start=ANALYSIS_START,\n",
    "    analysis_end=ANALYSIS_END\n",
    ")\n",
    "print(f\"Final df_final_tvl shape: {df_final_tvl.shape}\")\n",
    "print(f\"Excluded {len(excluded_list)} protocols due to filters or low TVL.\")\n",
    "\n",
    "# 10. Save final aggregated dataset\n",
    "df_final_tvl.to_csv(\"final_tvl_aggregate.csv\", index=False)\n",
    "print(\"Saved final_tvl_aggregate.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growth Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_tvl_agg: (129791, 6)\n",
      "Computing growth measures for categories: ['Liquid Staking' 'Restaking/Liquid Restaking' 'Lending' 'Trading' 'Yield'\n",
      " 'TradFi/Fintech' 'Stablecoins' 'Derivatives' 'Other'\n",
      " 'Staking/Liquid Staking' 'Services']\n",
      "\n",
      "Category => Liquid Staking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 761.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Restaking/Liquid Restaking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 840.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Lending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 613.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Trading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 461.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Yield\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:00<00:00, 648.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => TradFi/Fintech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 863.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Stablecoins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 676.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Derivatives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 494.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 883.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Staking/Liquid Staking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 845.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category => Services\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 528.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated growth measures. Sample:\n",
      "        protocol_name  chains_count  tvl_percent_growth  avg_tvl_rank  \\\n",
      "0                lido             1               0.133         0.860   \n",
      "1  binance-staked-eth             1               1.399         2.094   \n",
      "2         rocket-pool             1              -0.303         2.206   \n",
      "3       meth-protocol             1               0.112         3.440   \n",
      "4          stakestone             1              -0.233         3.296   \n",
      "\n",
      "   logistic_growth_rate  avg_mom_growth_abs  avg_mom_growth_percent  \\\n",
      "0                 0.055       859712684.403                   0.042   \n",
      "1                 0.244       665169255.675                   0.202   \n",
      "2                -0.065      -243103369.212                  -0.061   \n",
      "3                 0.045        35720830.444                   0.035   \n",
      "4                -0.420       -25749239.840                  -0.044   \n",
      "\n",
      "  protocol_category  \n",
      "0    Liquid Staking  \n",
      "1    Liquid Staking  \n",
      "2    Liquid Staking  \n",
      "3    Liquid Staking  \n",
      "4    Liquid Staking  \n",
      "Saved 'protocol_growth_metrics.csv' with shape: (410, 8)\n"
     ]
    }
   ],
   "source": [
    "# growth_calculations.py\n",
    "\n",
    "\"\"\"\n",
    "Part 3: Growth Calculations\n",
    "---------------------------\n",
    "Loads 'final_tvl_aggregate.csv', computes monthly logistic growth rate, \n",
    "MoM growth, and overall percent growth. Exports 'protocol_growth_metrics.csv'.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "FINAL_AGGREGATE_PATH = \"final_tvl_aggregate.csv\"\n",
    "GROWTH_OUTPUT_PATH = \"protocol_growth_metrics.csv\"\n",
    "\n",
    "df_tvl_agg = pd.read_csv(FINAL_AGGREGATE_PATH)\n",
    "print(f\"Loaded df_tvl_agg: {df_tvl_agg.shape}\")\n",
    "\n",
    "def extract_monthly_tvl(df_protocol_slice, start_period, months_count):\n",
    "    \"\"\"\n",
    "    Resamples TVL at monthly intervals. \n",
    "    Returns a Series indexed by each month.\n",
    "    \"\"\"\n",
    "    df_protocol_slice = df_protocol_slice.set_index(\"dt\")\n",
    "    monthly_series = df_protocol_slice[\"app_token_tvl_usd\"].resample(\"M\").last()\n",
    "    full_month_range = pd.date_range(start=start_period, periods=months_count, freq=\"M\")\n",
    "    monthly_series = monthly_series.reindex(full_month_range)\n",
    "    return monthly_series\n",
    "\n",
    "def fit_logistic_growth(monthly_values):\n",
    "    \"\"\"\n",
    "    Fits logistic curve: K / (1 + exp(-r(x - t0))) \n",
    "    and returns the 'r' (growth rate).\n",
    "    \"\"\"\n",
    "    monthly_values = monthly_values.dropna()\n",
    "    if len(monthly_values) < 3:\n",
    "        return None\n",
    "    time_index = np.arange(len(monthly_values))\n",
    "    y_vals = monthly_values.values\n",
    "\n",
    "    guess_k = max(y_vals)\n",
    "    guess_r = 1.0\n",
    "    guess_t0 = np.median(time_index)\n",
    "    try:\n",
    "        popt, _ = curve_fit(\n",
    "            lambda x, K, r, t0: K / (1 + np.exp(-r*(x - t0))),\n",
    "            time_index, y_vals,\n",
    "            p0=[guess_k, guess_r, guess_t0],\n",
    "            maxfev=10000\n",
    "        )\n",
    "        return popt[1]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def calculate_percent_growth(monthly_values):\n",
    "    monthly_values = monthly_values.dropna()\n",
    "    if len(monthly_values) < 2 or monthly_values.iloc[0] == 0:\n",
    "        return None\n",
    "    return (monthly_values.iloc[-1] - monthly_values.iloc[0]) / monthly_values.iloc[0]\n",
    "\n",
    "def calculate_average_mom_growth(monthly_values):\n",
    "    monthly_values = monthly_values.dropna()\n",
    "    if len(monthly_values) < 2:\n",
    "        return None, None\n",
    "    diffs = monthly_values.diff().dropna()\n",
    "    avg_abs_diff = diffs.mean()\n",
    "    avg_pct_diff = (diffs / monthly_values.shift(1)).mean()\n",
    "    return avg_abs_diff, avg_pct_diff\n",
    "\n",
    "def compute_weighted_ranks(monthly_data_dict):\n",
    "    monthly_df = pd.DataFrame(monthly_data_dict)\n",
    "    rank_df = monthly_df.rank(axis=1, method=\"min\", ascending=False)\n",
    "    weights = np.log1p(np.arange(1, len(rank_df)+1))\n",
    "    weights = weights / weights.sum()\n",
    "    weighted_ranks = (rank_df * weights[:, None]).sum()\n",
    "    return weighted_ranks\n",
    "\n",
    "def analyze_growth_for_category(category_name, df_input, months_window=4, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    For each protocol within a given category, resample monthly,\n",
    "    compute logistic growth, percent growth, MoM growth, etc.\n",
    "    \"\"\"\n",
    "    df_cat_slice = df_input[df_input[\"protocol_category\"] == category_name].copy()\n",
    "    df_cat_slice[\"dt\"] = pd.to_datetime(df_cat_slice[\"dt\"], errors=\"coerce\")\n",
    "    protocol_list = df_cat_slice[\"protocol_name\"].unique()\n",
    "\n",
    "    if cutoff_date:\n",
    "        cutoff_date = pd.to_datetime(cutoff_date)\n",
    "\n",
    "    excluded_info = []\n",
    "    results_data = []\n",
    "    monthly_tvl_records = {}\n",
    "\n",
    "    for proto in tqdm(protocol_list):\n",
    "        df_proto = df_cat_slice[df_cat_slice[\"protocol_name\"] == proto]\n",
    "        if df_proto.empty:\n",
    "            excluded_info.append({\"protocol\": proto, \"reason\": \"No data\"})\n",
    "            continue\n",
    "\n",
    "        if cutoff_date:\n",
    "            df_proto = df_proto[df_proto[\"dt\"] <= cutoff_date]\n",
    "        latest_date = df_proto[\"dt\"].max()\n",
    "        if pd.isna(latest_date):\n",
    "            excluded_info.append({\"protocol\": proto, \"reason\": \"No valid dt\"})\n",
    "            continue\n",
    "\n",
    "        end_period = latest_date.replace(day=1)\n",
    "        start_period = end_period - pd.DateOffset(months=months_window-1)\n",
    "        monthly_series = extract_monthly_tvl(df_proto, start_period, months_window)\n",
    "\n",
    "        if monthly_series.isna().any():\n",
    "            excluded_info.append({\"protocol\": proto, \"reason\": \"NaN in monthly TVL\"})\n",
    "            continue\n",
    "\n",
    "        monthly_tvl_records[proto] = monthly_series\n",
    "\n",
    "    # Weighted rank approach\n",
    "    average_ranks = compute_weighted_ranks(monthly_tvl_records)\n",
    "\n",
    "    for proto_name, series_vals in monthly_tvl_records.items():\n",
    "        percent_growth_val = calculate_percent_growth(series_vals)\n",
    "        if percent_growth_val is None:\n",
    "            excluded_info.append({\"protocol\": proto_name, \"reason\": \"Invalid percent growth\"})\n",
    "            continue\n",
    "\n",
    "        logistic_r_val = fit_logistic_growth(series_vals)\n",
    "        if logistic_r_val is None:\n",
    "            excluded_info.append({\"protocol\": proto_name, \"reason\": \"Invalid logistic fit\"})\n",
    "            continue\n",
    "\n",
    "        abs_mom_val, pct_mom_val = calculate_average_mom_growth(series_vals)\n",
    "        df_proto_slice = df_cat_slice[df_cat_slice[\"protocol_name\"] == proto_name]\n",
    "        chain_count_val = df_proto_slice[\"chains_count\"].iloc[0] if not df_proto_slice.empty else 1\n",
    "\n",
    "        results_data.append({\n",
    "            \"protocol_name\": proto_name,\n",
    "            \"chains_count\": chain_count_val,\n",
    "            \"tvl_percent_growth\": percent_growth_val,\n",
    "            \"avg_tvl_rank\": average_ranks[proto_name],\n",
    "            \"logistic_growth_rate\": logistic_r_val,\n",
    "            \"avg_mom_growth_abs\": abs_mom_val,\n",
    "            \"avg_mom_growth_percent\": pct_mom_val\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results_data), pd.DataFrame(excluded_info)\n",
    "\n",
    "def process_growth_for_all_categories(df_input, months_span=6, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    Iterates through all protocol categories, collects growth stats \n",
    "    into a combined DataFrame.\n",
    "    \"\"\"\n",
    "    df_input[\"dt\"] = pd.to_datetime(df_input[\"dt\"], errors=\"coerce\")\n",
    "    if cutoff_date:\n",
    "        cutoff_date = pd.to_datetime(cutoff_date)\n",
    "    else:\n",
    "        cutoff_date = df_input[\"dt\"].max()\n",
    "\n",
    "    unique_categories = df_input[\"protocol_category\"].unique()\n",
    "    print(\"Computing growth measures for categories:\", unique_categories)\n",
    "\n",
    "    combined_results_list = []\n",
    "    combined_excluded_list = []\n",
    "\n",
    "    for cat_item in unique_categories:\n",
    "        print(f\"\\nCategory => {cat_item}\")\n",
    "        cat_df, cat_excluded = analyze_growth_for_category(\n",
    "            category_name=cat_item,\n",
    "            df_input=df_input,\n",
    "            months_window=months_span,\n",
    "            cutoff_date=cutoff_date\n",
    "        )\n",
    "        cat_df[\"protocol_category\"] = cat_item\n",
    "\n",
    "        if not cat_df.empty:\n",
    "            combined_results_list.append(cat_df)\n",
    "        if not cat_excluded.empty:\n",
    "            combined_excluded_list.append(cat_excluded)\n",
    "\n",
    "    if combined_results_list:\n",
    "        df_growth = pd.concat(combined_results_list, ignore_index=True)\n",
    "    else:\n",
    "        df_growth = pd.DataFrame()\n",
    "\n",
    "    if combined_excluded_list:\n",
    "        df_excluded = pd.concat(combined_excluded_list, ignore_index=True)\n",
    "    else:\n",
    "        df_excluded = pd.DataFrame()\n",
    "\n",
    "    return df_growth, df_excluded\n",
    "\n",
    "# def main():\n",
    "df_tvl_agg[\"dt\"] = pd.to_datetime(df_tvl_agg[\"dt\"], errors=\"coerce\")\n",
    "final_growth_df, excluded_df = process_growth_for_all_categories(\n",
    "    df_input=df_tvl_agg,\n",
    "    months_span=6,\n",
    "    cutoff_date=\"2024-12-01\"\n",
    ")\n",
    "print(\"Calculated growth measures. Sample:\")\n",
    "print(final_growth_df.head())\n",
    "\n",
    "# Save\n",
    "final_growth_df.to_csv(GROWTH_OUTPUT_PATH, index=False)\n",
    "print(f\"Saved '{GROWTH_OUTPUT_PATH}' with shape:\", final_growth_df.shape)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "protocol_category\n",
       "Trading                       35666\n",
       "Yield                         33325\n",
       "Lending                       23948\n",
       "TradFi/Fintech                14205\n",
       "Derivatives                    7873\n",
       "Liquid Staking                 7673\n",
       "Restaking/Liquid Restaking     4665\n",
       "Stablecoins                    1826\n",
       "Services                        336\n",
       "Other                           269\n",
       "Staking/Liquid Staking            5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tvl_agg[\"protocol_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "protocol_category\n",
       "Trading                       110\n",
       "Yield                         106\n",
       "Lending                        76\n",
       "TradFi/Fintech                 47\n",
       "Derivatives                    24\n",
       "Liquid Staking                 23\n",
       "Restaking/Liquid Restaking     17\n",
       "Stablecoins                     5\n",
       "Other                           1\n",
       "Services                        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_growth_df[\"protocol_category\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
