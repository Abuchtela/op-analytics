{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../helper_functions'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests as r\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "sys.path.append(\"../../helper_functions\")\n",
    "import clickhouse_utils as ch\n",
    "sys.path.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_49589/3329598336.py:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  ['op',True]\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_49589/3329598336.py:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  ['op',True]\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_49589/3329598336.py:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  ['op',True]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m end_date \u001b[38;5;241m=\u001b[39m datetime(\u001b[38;5;241m2024\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m27\u001b[39m)   \u001b[38;5;66;03m# Year, Month, Day\u001b[39;00m\n\u001b[1;32m      4\u001b[0m trailing_days \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m\n\u001b[1;32m      6\u001b[0m chain_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 7\u001b[0m         \u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m         ]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "client = ch.connect_to_clickhouse_db() #Default is OPLabs DB\n",
    "\n",
    "end_date = datetime(2024, 6, 27)   # Year, Month, Day\n",
    "trailing_days = 14\n",
    "\n",
    "chain_names = [\n",
    "        ['op',True],\n",
    "        ['base',False]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_fields = '''\n",
    "    'receipt_l1_blob_base_fee',\n",
    "\t'receipt_l1_blob_base_fee_scalar',\n",
    "\t'receipt_l1_base_fee_scalar',\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "        hash,\n",
    "\tnonce,\n",
    "\tblock_hash,\n",
    "\tblock_number,\n",
    "\ttransaction_index,\n",
    "\tfrom_address,\n",
    "\tto_address,\n",
    "\tvalue,\n",
    "\tgas,\n",
    "\tgas_price,\n",
    "\tsubstring(input,1,10) AS tx_method_id,\n",
    "\tmax_fee_per_gas,\n",
    "\tmax_priority_fee_per_gas,\n",
    "\ttransaction_type,\n",
    "\tblock_timestamp,\n",
    "\treceipt_cumulative_gas_used,\n",
    "\treceipt_gas_used,\n",
    "\treceipt_contract_address,\n",
    "\treceipt_effective_gas_price,\n",
    "\treceipt_root_hash,\n",
    "\treceipt_l1_fee,\n",
    "\treceipt_l1_gas_used,\n",
    "\treceipt_l1_gas_price,\n",
    "\treceipt_l1_fee_scalar,\n",
    "\t@extra_fields@\n",
    "\tchain\n",
    "FROM @chain_name@_transactions\n",
    "WHERE gas_price > 0\n",
    "        AND block_timestamp >= '@start_date@'\n",
    "        AND block_timestamp < '@end_date@'\n",
    "\n",
    "SETTINGS max_execution_time = 50000\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate start date\n",
    "start_date = end_date - timedelta(days=trailing_days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT did this\n",
    "for chain_info in chain_names:\n",
    "    chain_name, has_extra_fields = chain_info\n",
    "    result = None\n",
    "    print(f\"Starting processing for {chain_name}\")\n",
    "\n",
    "    csv_filename = f'csv_outputs/{chain_name}_{end_date.strftime(\"%Y%m%d\")}_{trailing_days}days_v.csv'\n",
    "    file_exists = os.path.isfile(csv_filename)\n",
    "\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        start_time = time.time()\n",
    "        day_start = current_date\n",
    "        day_end = min(day_start + timedelta(days=1), end_date)\n",
    "\n",
    "        q_run = query.replace('@chain_name@', chain_name)\n",
    "        q_run = q_run.replace('@start_date@', day_start.strftime('%Y-%m-%d'))\n",
    "        q_run = q_run.replace('@end_date@', day_end.strftime('%Y-%m-%d'))\n",
    "        if has_extra_fields:\n",
    "            q_run = q_run.replace('@extra_fields@', extra_fields)\n",
    "        else:\n",
    "            q_run = q_run.replace('@extra_fields@', '')\n",
    "\n",
    "        print(f\"Querying data for {day_start.date()}\")\n",
    "        result = client.query_df(q_run)\n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        if not file_exists and current_date == start_date:\n",
    "            # If it's the first run and file doesn't exist, create new file with header\n",
    "            result.to_csv(csv_filename, index=False, mode='w')\n",
    "            file_exists = True\n",
    "        else:\n",
    "            # Append without header\n",
    "            result.to_csv(csv_filename, index=False, mode='a', header=False)\n",
    "\n",
    "        int_time = time.time()\n",
    "        execution_time = int_time - start_time\n",
    "        print(f\"Query for {chain_name} on {day_start.date()} completed in {execution_time:.2f} seconds\")\n",
    "\n",
    "        current_date = day_end\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Processing for {chain_name} completed in {execution_time:.2f} seconds\")\n",
    "    print(f\"Processed data for {trailing_days} days, ending on {end_date.date()}\")\n",
    "    print(f\"Results saved to {csv_filename}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result.result_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
