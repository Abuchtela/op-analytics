{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245f7c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffefb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from op_analytics.coreutils.gcpauth import get_credentials\n",
    "from op_analytics.cli.subcommands.pulls.defillama.protocols import pull_protocol_tvl\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from op_analytics.coreutils.threads import run_concurrently\n",
    "\n",
    "from op_analytics.cli.subcommands.pulls.app import defillama_protocol_tvl\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "import urllib3\n",
    "import warnings\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "urllib3.disable_warnings()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf536b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0fc55e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERNS_TO_FILTER = [\n",
    "    \"-borrowed\",\n",
    "    \"-vesting\",\n",
    "    \"-staking\",\n",
    "    \"-pool2\",\n",
    "    \"-treasury\",\n",
    "    \"-cex\",\n",
    "    \"^treasury$\",\n",
    "    \"^borrowed$\",\n",
    "    \"^staking$\",\n",
    "    \"^pool2$\",\n",
    "    \"^pool2$\",\n",
    "    \"polygon-bridge-&-staking\",  # Added this as a full match\n",
    "    \".*-cex$\",  # Added this to match anything ending with -cex\n",
    "]\n",
    "\n",
    "CATEGORIES_TO_FILTER = [\"CEX\", \"Chain\"]\n",
    "\n",
    "alignment_dict = {\n",
    "    \"Metis\": \"OP Stack fork\",\n",
    "    \"Blast\": \"OP Stack fork\",\n",
    "    \"Mantle\": \"OP Stack fork\",\n",
    "    \"Zircuit\": \"OP Stack fork\",\n",
    "    \"RSS3\": \"OP Stack fork\",\n",
    "    \"Rollux\": \"OP Stack fork\",\n",
    "    \"Ancient8\": \"OP Stack fork\",\n",
    "    \"Manta\": \"OP Stack fork\",\n",
    "    \"Cyber\": \"OP Chain\",\n",
    "    \"Mint\": \"OP Chain\",\n",
    "    \"Ham\": \"OP Chain\",\n",
    "    \"Polynomial\": \"OP Chain\",\n",
    "    \"Lisk\": \"OP Chain\",\n",
    "    \"BOB\": \"OP Chain\",\n",
    "    \"Mode\": \"OP Chain\",\n",
    "    \"World Chain\": \"OP Chain\",\n",
    "    \"Base\": \"OP Chain\",\n",
    "    \"Kroma\": \"OP Chain\",\n",
    "    \"Boba\": \"OP Chain\",\n",
    "    \"Fraxtal\": \"OP Chain\",\n",
    "    \"Optimism\": \"OP Chain\",\n",
    "    \"Shape\": \"OP Chain\",\n",
    "    \"Zora\": \"OP Chain\"\n",
    "}\n",
    "\n",
    "alignment_df = pd.DataFrame(list(alignment_dict.items()), columns=[\"chain\", \"alignment\"])\n",
    "\n",
    "token_data = [\n",
    "    {\"token\": \"ETH\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"WETH\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"SOL\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"wBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "    {\"token\": \"cbBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "    {\"token\": \"MBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "\n",
    "    {\"token\": \"stETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"wstETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"eETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"weETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"sfrxETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"rETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"mETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"rsETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"cbETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"ezETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"rswETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"swETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"frxETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"ETHX\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"lsETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"oETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"EBTC\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"LBTC\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"SUPEROETHB\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"WSUPEROETHB\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"TETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"OSETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"cmETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"WRSETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"WEETH.BASE\", \"token_category\": \"Liquid Restaking\"},\n",
    "    \n",
    "    {\"token\": \"USDC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDT\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"FDUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"PYUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"TUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"DAI\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDE\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"FRAX\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"EURC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"AGEUR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDS\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDB\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"DOLA\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"SUSDE\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD0++\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD0\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"SUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"CRVUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDC+\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDZ\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"STAR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDBC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD+\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"CDXUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"HYUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"STAR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"EURS\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"AXLEUROC\", \"token_category\": \"Stablecoins\"},\n",
    "\n",
    "\n",
    "    # Solana Liquid staking\n",
    "    {\"token\": \"MSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"JUPSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"BNSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"SSOL\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"BBSOL\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"LAINESOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STRONGSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"HUBSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"PATHSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STEPSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"EDGESOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"JITOSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"DSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"BONKSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"VSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"HSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    # {\"token\": \"ARB\", \"token_category\": \"Layer 2 Token\"},\n",
    "    # {\"token\": \"OP\", \"token_category\": \"Layer 2 Token\"},\n",
    "    # {\"token\": \"MODE\", \"token_category\": \"Layer 2 Token\"},\n",
    "]\n",
    "\n",
    "token_categories = pd.DataFrame(token_data)\n",
    "\n",
    "token_categories[\"token\"] = token_categories[\"token\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504df9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534fff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weekly_date_ranges(start_date: str, end_date: str) -> list[tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate a list of weekly date ranges between a start and end date.\n",
    "    \"\"\"\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    date_ranges = []\n",
    "\n",
    "    while start <= end:\n",
    "        week_end = min(start + timedelta(days=6), end)\n",
    "        date_ranges.append((start.strftime(\"%Y-%m-%d\"), week_end.strftime(\"%Y-%m-%d\")))\n",
    "        start = week_end + timedelta(days=1)\n",
    "\n",
    "    return date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4d4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_big_query_concurrently(client, base_query, date_ranges, max_workers: int | None = None):\n",
    "    \n",
    "    max_workers = max_workers or 4\n",
    "\n",
    "    query_template = \"\"\"\n",
    "    {base_query}\n",
    "    WHERE dt BETWEEN '{start_date}' AND '{end_date}'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def fetch_chunk(start_date, end_date):\n",
    "        query = query_template.format(base_query=base_query, start_date=start_date, end_date=end_date)\n",
    "        query_job = client.query(query)\n",
    "        return query_job.to_dataframe()\n",
    "\n",
    "    dataframes = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(fetch_chunk, start, end): (start, end) for start, end in date_ranges}\n",
    "\n",
    "        with tqdm(total=len(futures), desc=\"Fetching Data\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                dataframes.append(future.result())\n",
    "                pbar.update(1)\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc63a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = bigquery.Client(credentials=get_credentials())\n",
    "# date_range = generate_weekly_date_ranges(\"2024-08-20\", \"2024-11-20\")\n",
    "\n",
    "# query = \"\"\"\n",
    "# SELECT \n",
    "#     tvl.protocol_slug,\n",
    "#     tvl.chain,\n",
    "#     m.protocol_name,\n",
    "#     m.parent_protocol,\n",
    "#     m.protocol_category,\n",
    "#     tvl.dt,\n",
    "#     tvl.token,\n",
    "#     tvl.app_token_tvl,\n",
    "#     tvl.app_token_tvl_usd\n",
    "# FROM `oplabs-tools-data.uploads_api.defillama_protocols_token_tvl` tvl \n",
    "# LEFT JOIN `oplabs-tools-data.uploads_api.defillama_protocols_metadata` m \n",
    "#     ON tvl.protocol_slug = m.protocol_slug\n",
    "# \"\"\"\n",
    "\n",
    "# df_bq = run_big_query_concurrently(client, query, date_range, max_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48ba470",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ProtocolTvlDataframes = pull_protocol_tvl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e64e4a9f-db55-4361-a366-458927fc4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = pd.merge(\n",
    "#     ProtocolTvlDataframes.metadata_df.to_pandas(), \n",
    "#     ProtocolTvlDataframes.app_token_tvl_df.to_pandas(), \n",
    "#     how=\"inner\",\n",
    "#     on=\"protocol_slug\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada54750-25a1-4f9d-bfb0-6b1c58bf3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "dd96c509-e0d7-48ed-a3c9-e8ce5739eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.to_csv(\"defillama_raw_protocol_token_tvl_2024-11-26.csv\", index=False)\n",
    "q = dedent(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        dt,\n",
    "        protocol_name,\n",
    "        protocol_slug,\n",
    "        protocol_category,\n",
    "        parent_protocol,\n",
    "        chain,\n",
    "        CASE WHEN misrepresented_tokens = 'True' THEN 1\n",
    "             WHEN misrepresented_tokens = 'False' THEN 0\n",
    "             ELSE 0\n",
    "        END AS misrepresented_tokens_flag,\n",
    "        token,\n",
    "        app_token_tvl,\n",
    "        app_token_tvl_usd\n",
    "    FROM 'defillama_raw_protocol_token_tvl_2024-11-26.csv'\n",
    "    WHERE dt >= '2024-08-01'\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "df_all = db.query(q).to_df()\n",
    "\n",
    "df_all = pd.merge(df_all, alignment_df, on=\"chain\", how=\"left\")\n",
    "df_all[\"alignment\"] = df_all[\"alignment\"].fillna(\"Other\")\n",
    "df_all = pd.merge(df_all, token_categories, on=\"token\", how=\"left\")\n",
    "df_all[\"token_category\"] = df_all[\"token_category\"].fillna(\"Other\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbdc40c-22f0-4457-912b-88ee3ffcf9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7d1c25dc-58a1-4c19-b8ca-17b3b36e4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain level misrepresented tokens\n",
    "df_misrep = (\n",
    "    df_all\n",
    "    [[\"protocol_slug\", \"chain\", \"misrepresented_tokens_flag\", \"token\"]]\n",
    "    .groupby([\"protocol_slug\", \"chain\", \"misrepresented_tokens_flag\"])\n",
    "    .agg(\n",
    "        token_count=(\"token\", \"nunique\"),\n",
    "        has_usdt=(\"token\", lambda x: 1 if \"USDT\" in x.values else 0)\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_misrep[\"chain_misrepresented_tokens_flag\"] = (\n",
    "    (df_misrep[\"misrepresented_tokens_flag\"] == 1) \n",
    "    & (df_misrep[\"token_count\"] == 1) \n",
    "    & (df_misrep[\"has_usdt\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "df_all = pd.merge(\n",
    "    df_all, \n",
    "    df_misrep[[\"protocol_slug\", \"chain\", \"chain_misrepresented_tokens_flag\"]], \n",
    "    on=[\"protocol_slug\", \"chain\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115af18e-e8e8-41f7-bfb4-d17046e8a8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "797379cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove protocols and chains\n",
    "\n",
    "def matches_filter_pattern(s):\n",
    "    return any(re.search(pattern, s, re.IGNORECASE) for pattern in PATTERNS_TO_FILTER)\n",
    "\n",
    "df_all[\"chain\"] = df_all[\"chain\"].astype(str)\n",
    "\n",
    "df_chain_protocol = df_all[[\"chain\", \"protocol_slug\", \"protocol_category\"]].drop_duplicates()\n",
    "\n",
    "df_chain_protocol[\"protocol_filters\"] = (\n",
    "    df_chain_protocol[\"chain\"].apply(matches_filter_pattern)\n",
    "    | (df_chain_protocol[\"protocol_slug\"] == \"polygon-bridge-&-staking\")\n",
    "    | df_chain_protocol[\"protocol_slug\"].str.endswith(\"-cex\")\n",
    "    | df_chain_protocol.protocol_category.isin(CATEGORIES_TO_FILTER)\n",
    ").astype(int)\n",
    "\n",
    "# small subset for analysis, actual logic will include more (all?) chains\n",
    "df_chain_protocol[\"chains_to_keep\"] = (\n",
    "    (df_all.alignment.isin([\"OP Chain\", \"OP Stack Fork\"]) \n",
    "    | df_all.chain.isin([\"Ethereum\", \"Arbitrum\", \"Solana\"]))\n",
    "    ).astype(int)\n",
    "\n",
    "filter_mask = (df_chain_protocol.protocol_filters == 0) & (df_chain_protocol.chains_to_keep == 1)\n",
    "\n",
    "df_filtered = pd.merge(\n",
    "    df_all,\n",
    "    df_chain_protocol[filter_mask][[\"chain\", \"protocol_slug\", \"protocol_category\"]],\n",
    "    on=[\"chain\", \"protocol_slug\", \"protocol_category\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f6f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "537bf0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"dt\"] = pd.to_datetime(df_filtered[\"dt\"])\n",
    "df_filtered[\"parent_protocol\"] = df_filtered[\"parent_protocol\"].str.replace(\"parent#\", \"\")\n",
    "df_filtered[\"token\"] = df_filtered[\"token\"].str.upper()\n",
    "df_filtered[\"token_category\"] = df_filtered[\"token_category\"].fillna(\"Other\")\n",
    "\n",
    "df_filtered[\"token_category_misrep\"] = np.where(\n",
    "    (df_filtered.chain_misrepresented_tokens_flag == 1),\n",
    "    \"Misrepresented TVL\", \n",
    "    df_filtered.token_category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6e146-592b-4b5f-9ecb-a076b4d69400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d65c26a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "15047c01-59ab-44f6-8794-2d718b945fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af5008-c5f1-4e1d-97c8-b27c689c1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some treemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b566f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_category_breakdown = df_filtered.groupby([\"dt\", \"chain\", \"token_category_misrep\", \"protocol_category\"]).agg(\n",
    "    {\"app_token_tvl_usd\": \"sum\"}\n",
    ").reset_index().rename(columns={\"token_category_misrep\": \"token_category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a7cdf785",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_category_breakdown[\"dt\"] = pd.to_datetime(token_category_breakdown[\"dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "62d530c5-857d-4236-a157-ba6a6b60ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def plot_nested_token_category_breakdown(data, date, chain, date_diff=90):\n",
    "\n",
    "    data[\"dt\"] = pd.to_datetime(data[\"dt\"])\n",
    "    target_date = pd.to_datetime(date)\n",
    "    previous_date = (target_date - pd.Timedelta(days=date_diff)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # filter to 10k min TVL for current date\n",
    "    filtered_data = data[\n",
    "        (data[\"dt\"] == target_date) & (data[\"chain\"] == chain) & (data[\"app_token_tvl_usd\"] >= 10_000)\n",
    "    ]\n",
    "\n",
    "    # no lower bound\n",
    "    previous_data = data[\n",
    "        (data[\"dt\"] == previous_date) & (data[\"chain\"] == chain)\n",
    "    ]\n",
    "\n",
    "    merged_data = filtered_data.merge(\n",
    "        previous_data[[\"token_category\", \"protocol_category\", \"app_token_tvl_usd\"]],\n",
    "        on=[\"token_category\", \"protocol_category\"],\n",
    "        suffixes=(\"\", \"_previous\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # avoid dividing by zero\n",
    "    merged_data[\"app_token_tvl_usd_previous\"].fillna(0.01, inplace=True)\n",
    "\n",
    "    merged_data[\"percent_change\"] = (\n",
    "        (merged_data[\"app_token_tvl_usd\"] - merged_data[\"app_token_tvl_usd_previous\"])\n",
    "        / merged_data[\"app_token_tvl_usd_previous\"]\n",
    "    ) * 100\n",
    "\n",
    "    # cap percent changes\n",
    "    merged_data[\"percent_change\"] = merged_data[\"percent_change\"].clip(lower=-1000, upper=1000)\n",
    "\n",
    "    fig = px.treemap(\n",
    "        merged_data,\n",
    "        path=[px.Constant(\"Total\"), \"token_category\", \"protocol_category\"],\n",
    "        values=\"app_token_tvl_usd\", \n",
    "        color=\"percent_change\", \n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        range_color=[-100, 100], \n",
    "        title=f\"{chain}: Token Category <> App TVL Last {date_diff} Days\",\n",
    "        width=600,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a16005-dfaa-4e51-acf7-76723843191b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0c338da6-23a9-4f09-bfda-b409c5cc8949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"620px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_221.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = plot_nested_token_category_breakdown(token_category_breakdown, \"2024-11-20\", \"Base\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7e868be5-591c-4661-bba5-1e35563f6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_breakdown = df_filtered.groupby([\"dt\", \"chain\", \"token_category_misrep\", \"protocol_category\", \"token\"]).agg(\n",
    "    {\"app_token_tvl_usd\": \"sum\"}\n",
    ").reset_index().rename(columns={\"token_category_misrep\": \"token_category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "28b7c4d2-6090-4632-8fb9-36f7391f6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nested_token_breakdown(data, date, chain, date_diff=90):\n",
    "\n",
    "    data[\"dt\"] = pd.to_datetime(data[\"dt\"])\n",
    "    target_date = pd.to_datetime(date)\n",
    "    previous_date = (target_date - pd.Timedelta(days=date_diff)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    filtered_data = data[\n",
    "        (data[\"dt\"] == target_date) & (data[\"chain\"] == chain) & (data[\"app_token_tvl_usd\"] >= 10_000)\n",
    "    ]\n",
    "\n",
    "    previous_data = data[\n",
    "        (data[\"dt\"] == previous_date) & (data[\"chain\"] == chain)\n",
    "    ]\n",
    "\n",
    "    merged_data = filtered_data.merge(\n",
    "        previous_data[[\"token_category\", \"protocol_category\", \"token\", \"app_token_tvl_usd\"]],\n",
    "        on=[\"token_category\", \"protocol_category\", \"token\"],\n",
    "        suffixes=(\"\", \"_previous\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    merged_data[\"app_token_tvl_usd_previous\"].fillna(0.01, inplace=True)\n",
    "\n",
    "    merged_data[\"percent_change\"] = (\n",
    "        (merged_data[\"app_token_tvl_usd\"] - merged_data[\"app_token_tvl_usd_previous\"])\n",
    "        / merged_data[\"app_token_tvl_usd_previous\"]\n",
    "    ) * 100\n",
    "\n",
    "    merged_data[\"percent_change\"] = merged_data[\"percent_change\"].clip(lower=-500, upper=500)\n",
    "\n",
    "    fig = px.treemap(\n",
    "        merged_data,\n",
    "        path=[px.Constant(\"Total\"), \"token_category\", \"protocol_category\", \"token\"],\n",
    "        values=\"app_token_tvl_usd\", \n",
    "        color=\"percent_change\", \n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        range_color=[-100, 100], \n",
    "        title=f\"{chain}: Token Category <> App TVL Last {date_diff} Days\",\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925a33a-8273-4705-adbc-e00fdc6aa04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2a90aad8-0f85-4980-8e24-b511ec3a486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_breakdown = df_filtered.groupby([\"dt\", \"chain\", \"token_category_misrep\", \"protocol_category\", \"token\"]).agg(\n",
    "    {\"app_token_tvl_usd\": \"sum\"}\n",
    ").reset_index().rename(columns={\"token_category_misrep\": \"token_category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3fbd96ac-63d8-433f-b00e-e9c5b7cc66da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_293.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = plot_nested_token_breakdown(token_breakdown, \"2024-11-20\", \"Base\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333644d-d11e-4e65-9405-10cd9e76cb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "dbb3b0fe-73f0-4c2f-b29f-de8292c8d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_breakdown = df_filtered.groupby([\"dt\", \"chain\", \"protocol_category\", \"parent_protocol\", \"token_category_misrep\"]).agg(\n",
    "    {\"app_token_tvl_usd\": \"sum\"}\n",
    ").reset_index().rename(columns={\"token_category_misrep\": \"token_category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9b3c119d-a056-4719-821d-707e5770a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nested_protocol_breakdown(data, date, chain, date_diff=90):\n",
    "\n",
    "    data[\"dt\"] = pd.to_datetime(data[\"dt\"])\n",
    "    target_date = pd.to_datetime(date)\n",
    "    previous_date = (target_date - pd.Timedelta(days=date_diff)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    filtered_data = data[\n",
    "        (data[\"dt\"] == target_date) & (data[\"chain\"] == chain) & (data[\"app_token_tvl_usd\"] >= 10_000)\n",
    "    ]\n",
    "\n",
    "    previous_data = data[\n",
    "        (data[\"dt\"] == previous_date) & (data[\"chain\"] == chain)\n",
    "    ]\n",
    "\n",
    "    merged_data = filtered_data.merge(\n",
    "        previous_data[[ \"protocol_category\", \"parent_protocol\", \"token_category\", \"app_token_tvl_usd\"]],\n",
    "        on=[ \"protocol_category\", \"parent_protocol\", \"token_category\"],\n",
    "        suffixes=(\"\", \"_previous\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    merged_data[\"app_token_tvl_usd_previous\"].fillna(0.01, inplace=True)\n",
    "\n",
    "    merged_data[\"percent_change\"] = (\n",
    "        (merged_data[\"app_token_tvl_usd\"] - merged_data[\"app_token_tvl_usd_previous\"])\n",
    "        / merged_data[\"app_token_tvl_usd_previous\"]\n",
    "    ) * 100\n",
    "\n",
    "    merged_data[\"percent_change\"] = merged_data[\"percent_change\"].clip(lower=-500, upper=500)\n",
    "\n",
    "    fig = px.treemap(\n",
    "        merged_data,\n",
    "        path=[px.Constant(\"Total\"), \"protocol_category\", \"parent_protocol\", \"token_category\"],\n",
    "        values=\"app_token_tvl_usd\", \n",
    "        color=\"percent_change\", \n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        range_color=[-100, 100],\n",
    "        title=f\"{chain}: Token Category <> App TVL Last {date_diff} Days\",\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return merged_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "340d1b60-0ee5-4411-b947-f54fab4f0f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_308.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = plot_nested_protocol_breakdown(protocol_breakdown, \"2024-11-20\", \"Solana\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e998ff7-5201-433f-b397-5acbdaa578e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "74a4f01b-9dc2-4681-a2de-d43005e4cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_token_breakdown = df_filtered.groupby([\"dt\", \"chain\", \"protocol_category\", \"parent_protocol\", \"token_category_misrep\",  \"token\"]).agg(\n",
    "    {\"app_token_tvl_usd\": \"sum\"}\n",
    ").reset_index().rename(columns={\"token_category_misrep\": \"token_category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "974a5163-6367-4c39-a67b-f84ae0c084d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nested_protocol_token_breakdown(data, date, chain, date_diff=90):\n",
    "\n",
    "    data[\"dt\"] = pd.to_datetime(data[\"dt\"])\n",
    "    target_date = pd.to_datetime(date)\n",
    "    previous_date = (target_date - pd.Timedelta(days=date_diff)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    filtered_data = data[\n",
    "        (data[\"dt\"] == target_date) & (data[\"chain\"] == chain) & (data[\"app_token_tvl_usd\"] >= 10_000)\n",
    "    ]\n",
    "\n",
    "    previous_data = data[\n",
    "        (data[\"dt\"] == previous_date) & (data[\"chain\"] == chain)\n",
    "    ]\n",
    "\n",
    "    merged_data = filtered_data.merge(\n",
    "        previous_data[[ \"protocol_category\", \"parent_protocol\", \"token_category\", \"token\", \"app_token_tvl_usd\"]],\n",
    "        on=[ \"protocol_category\", \"parent_protocol\", \"token_category\", \"token\"],\n",
    "        suffixes=(\"\", \"_previous\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    merged_data[\"app_token_tvl_usd_previous\"].fillna(0.01, inplace=True)\n",
    "\n",
    "    merged_data[\"percent_change\"] = (\n",
    "        (merged_data[\"app_token_tvl_usd\"] - merged_data[\"app_token_tvl_usd_previous\"])\n",
    "        / merged_data[\"app_token_tvl_usd_previous\"]\n",
    "    ) * 100\n",
    "\n",
    "    merged_data[\"percent_change\"] = merged_data[\"percent_change\"].clip(lower=-500, upper=500)\n",
    "\n",
    "    fig = px.treemap(\n",
    "        merged_data,\n",
    "        path=[px.Constant(\"Total\"), \"protocol_category\", \"parent_protocol\", \"token_category\", \"token\"], \n",
    "        values=\"app_token_tvl_usd\", \n",
    "        color=\"percent_change\",\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        range_color=[-100, 100], \n",
    "        title=f\"{chain}: Token Category <> App TVL Last {date_diff} Days\",\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e984c76c-74ab-4425-9f37-8e4888208a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_315.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = plot_nested_protocol_token_breakdown(protocol_token_breakdown, \"2024-11-20\", \"Solana\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af93cb-80af-4365-bc66-25b6afbd0f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddabd13-da78-480b-ac0c-2ddf18260695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "op-analytics",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
